<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - coverage_filtered.info - nntrainer/layers/lstm.cpp</title>
  <link rel="stylesheet" type="text/css" href="../../gcov.css">
</head>

<body>

          <table width="100%" border=0 cellspacing=0 cellpadding=0>
            <tr><td class="title">LCOV - code coverage report</td></tr>
            <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>

            <tr>
              <td width="100%">
                <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="10%" class="headerValue"><a href="../../index.html">top level</a> - <a href="index.html">nntrainer/layers</a> - lstm.cpp<span style="font-size: 80%;"> (source / <a href="lstm.cpp.func-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="5%"></td>
            <td width="5%" class="headerCovTableHead">Coverage</td>
            <td width="5%" class="headerCovTableHead" title="Covered + Uncovered code">Total</td>
            <td width="5%" class="headerCovTableHead" title="Exercised code only">Hit</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">coverage_filtered.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntryLo">73.8&nbsp;%</td>
            <td class="headerCovTableEntry">447</td>
            <td class="headerCovTableEntry">330</td>
          </tr>
          <tr>
            <td class="headerItem">Test Date:</td>
            <td class="headerValue">2025-12-17 20:40:36</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntryMed">83.3&nbsp;%</td>
            <td class="headerCovTableEntry">12</td>
            <td class="headerCovTableEntry">10</td>
          </tr>
                  <tr><td><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
                </table>
              </td>
            </tr>

            <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
          </table>

          <table cellpadding=0 cellspacing=0 border=0>
            <tr>
              <td><br></td>
            </tr>
            <tr>
              <td>
<pre class="sourceHeading">            Line data    Source code</pre>
<pre class="source">
<span id="L1"><span class="lineNum">       1</span>              : // SPDX-License-Identifier: Apache-2.0</span>
<span id="L2"><span class="lineNum">       2</span>              : /**</span>
<span id="L3"><span class="lineNum">       3</span>              :  * Copyright (C) 2020 Jijoong Moon &lt;jijoong.moon@samsung.com&gt;</span>
<span id="L4"><span class="lineNum">       4</span>              :  *</span>
<span id="L5"><span class="lineNum">       5</span>              :  * @file   lstm.cpp</span>
<span id="L6"><span class="lineNum">       6</span>              :  * @date   17 March 2021</span>
<span id="L7"><span class="lineNum">       7</span>              :  * @brief  This is Long Short-Term Memory Layer Class of Neural Network</span>
<span id="L8"><span class="lineNum">       8</span>              :  * @see    https://github.com/nnstreamer/nntrainer</span>
<span id="L9"><span class="lineNum">       9</span>              :  * @author Jijoong Moon &lt;jijoong.moon@samsung.com&gt;</span>
<span id="L10"><span class="lineNum">      10</span>              :  * @bug    No known bugs except for NYI items</span>
<span id="L11"><span class="lineNum">      11</span>              :  *</span>
<span id="L12"><span class="lineNum">      12</span>              :  */</span>
<span id="L13"><span class="lineNum">      13</span>              : </span>
<span id="L14"><span class="lineNum">      14</span>              : #include &lt;layer_context.h&gt;</span>
<span id="L15"><span class="lineNum">      15</span>              : #include &lt;lstm.h&gt;</span>
<span id="L16"><span class="lineNum">      16</span>              : #include &lt;nntr_threads.h&gt;</span>
<span id="L17"><span class="lineNum">      17</span>              : #include &lt;nntrainer_error.h&gt;</span>
<span id="L18"><span class="lineNum">      18</span>              : #include &lt;nntrainer_log.h&gt;</span>
<span id="L19"><span class="lineNum">      19</span>              : #include &lt;node_exporter.h&gt;</span>
<span id="L20"><span class="lineNum">      20</span>              : </span>
<span id="L21"><span class="lineNum">      21</span>              : namespace nntrainer {</span>
<span id="L22"><span class="lineNum">      22</span>              : </span>
<span id="L23"><span class="lineNum">      23</span>              : static constexpr size_t SINGLE_INOUT_IDX = 0;</span>
<span id="L24"><span class="lineNum">      24</span>              : </span>
<span id="L25"><span class="lineNum">      25</span>              : enum LSTMParams {</span>
<span id="L26"><span class="lineNum">      26</span>              :   weight_ih,</span>
<span id="L27"><span class="lineNum">      27</span>              :   weight_hh,</span>
<span id="L28"><span class="lineNum">      28</span>              :   bias_h,</span>
<span id="L29"><span class="lineNum">      29</span>              :   bias_ih,</span>
<span id="L30"><span class="lineNum">      30</span>              :   bias_hh,</span>
<span id="L31"><span class="lineNum">      31</span>              :   hidden_state,</span>
<span id="L32"><span class="lineNum">      32</span>              :   cell_state,</span>
<span id="L33"><span class="lineNum">      33</span>              :   ifgo,</span>
<span id="L34"><span class="lineNum">      34</span>              :   reverse_weight_ih,</span>
<span id="L35"><span class="lineNum">      35</span>              :   reverse_weight_hh,</span>
<span id="L36"><span class="lineNum">      36</span>              :   reverse_bias_h,</span>
<span id="L37"><span class="lineNum">      37</span>              :   reverse_bias_ih,</span>
<span id="L38"><span class="lineNum">      38</span>              :   reverse_bias_hh,</span>
<span id="L39"><span class="lineNum">      39</span>              :   reverse_hidden_state,</span>
<span id="L40"><span class="lineNum">      40</span>              :   reverse_cell_state,</span>
<span id="L41"><span class="lineNum">      41</span>              :   reverse_ifgo,</span>
<span id="L42"><span class="lineNum">      42</span>              :   dropout_mask</span>
<span id="L43"><span class="lineNum">      43</span>              : };</span>
<span id="L44"><span class="lineNum">      44</span>              : </span>
<span id="L45"><span class="lineNum">      45</span> <span class="tlaGNC tlaBgGNC">         189 : void LSTMLayer::forwardingBatchFirstLSTM(</span></span>
<span id="L46"><span class="lineNum">      46</span>              :   unsigned int NUM_GATE, const unsigned int batch_size,</span>
<span id="L47"><span class="lineNum">      47</span>              :   const unsigned int feature_size, const bool disable_bias,</span>
<span id="L48"><span class="lineNum">      48</span>              :   const unsigned int unit, const bool integrate_bias, ActiFunc &amp;acti_func,</span>
<span id="L49"><span class="lineNum">      49</span>              :   ActiFunc &amp;recurrent_acti_func, const bool enable_dropout,</span>
<span id="L50"><span class="lineNum">      50</span>              :   const float dropout_rate, const unsigned int max_timestep, const bool reverse,</span>
<span id="L51"><span class="lineNum">      51</span>              :   const Tensor &amp;input_, const Tensor &amp;weight_ih, const Tensor &amp;weight_hh,</span>
<span id="L52"><span class="lineNum">      52</span>              :   const Tensor &amp;bias_h, const Tensor &amp;bias_ih, const Tensor &amp;bias_hh,</span>
<span id="L53"><span class="lineNum">      53</span>              :   Tensor &amp;hidden_state_, Tensor &amp;cell_state_, Tensor &amp;ifgo_,</span>
<span id="L54"><span class="lineNum">      54</span>              :   const Tensor &amp;mask_) {</span>
<span id="L55"><span class="lineNum">      55</span> <span class="tlaGNC">         189 :   hidden_state_.setZero();</span></span>
<span id="L56"><span class="lineNum">      56</span> <span class="tlaGNC">         189 :   cell_state_.setZero();</span></span>
<span id="L57"><span class="lineNum">      57</span> <span class="tlaGNC">         189 :   TensorDim::TensorType tensor_type = weight_ih.getTensorType();</span></span>
<span id="L58"><span class="lineNum">      58</span> <span class="tlaGNC">         189 :   TensorDim input_tensor_dim({feature_size}, tensor_type);</span></span>
<span id="L59"><span class="lineNum">      59</span> <span class="tlaGNC">         189 :   TensorDim unit_tensor_dim({unit}, tensor_type);</span></span>
<span id="L60"><span class="lineNum">      60</span> <span class="tlaGNC">         189 :   TensorDim num_gate_unit_tensor_dim({NUM_GATE * unit}, tensor_type);</span></span>
<span id="L61"><span class="lineNum">      61</span>              : </span>
<span id="L62"><span class="lineNum">      62</span> <span class="tlaGNC">         591 :   for (unsigned int batch = 0; batch &lt; batch_size; ++batch) {</span></span>
<span id="L63"><span class="lineNum">      63</span> <span class="tlaGNC">         402 :     const Tensor input_sample = input_.getBatchSlice(batch, 1);</span></span>
<span id="L64"><span class="lineNum">      64</span> <span class="tlaGNC">         402 :     Tensor hidden_state_sample = hidden_state_.getBatchSlice(batch, 1);</span></span>
<span id="L65"><span class="lineNum">      65</span> <span class="tlaGNC">         402 :     Tensor cell_state_sample = cell_state_.getBatchSlice(batch, 1);</span></span>
<span id="L66"><span class="lineNum">      66</span> <span class="tlaGNC">         402 :     Tensor ifgo_sample = ifgo_.getBatchSlice(batch, 1);</span></span>
<span id="L67"><span class="lineNum">      67</span>              : </span>
<span id="L68"><span class="lineNum">      68</span> <span class="tlaGNC">        1281 :     for (unsigned int t = 0; t &lt; max_timestep; ++t) {</span></span>
<span id="L69"><span class="lineNum">      69</span>              :       Tensor input = input_sample.getSharedDataTensor(</span>
<span id="L70"><span class="lineNum">      70</span> <span class="tlaGNC">         879 :         input_tensor_dim, (reverse ? max_timestep - 1 - t : t) * feature_size);</span></span>
<span id="L71"><span class="lineNum">      71</span>              : </span>
<span id="L72"><span class="lineNum">      72</span>              :       Tensor prev_hidden_state = Tensor(</span>
<span id="L73"><span class="lineNum">      73</span> <span class="tlaGNC">         879 :         &quot;prev_hidden_state&quot;, weight_ih.getFormat(), weight_ih.getDataType());</span></span>
<span id="L74"><span class="lineNum">      74</span>              : </span>
<span id="L75"><span class="lineNum">      75</span> <span class="tlaGNC">         879 :       if (!t) {</span></span>
<span id="L76"><span class="lineNum">      76</span> <span class="tlaGNC">         804 :         prev_hidden_state = Tensor(unit, tensor_type);</span></span>
<span id="L77"><span class="lineNum">      77</span> <span class="tlaGNC">         402 :         prev_hidden_state.setZero();</span></span>
<span id="L78"><span class="lineNum">      78</span>              :       } else {</span>
<span id="L79"><span class="lineNum">      79</span> <span class="tlaGNC">        1431 :         prev_hidden_state = hidden_state_sample.getSharedDataTensor(</span></span>
<span id="L80"><span class="lineNum">      80</span> <span class="tlaGNC">         477 :           unit_tensor_dim, (reverse ? (max_timestep - t) : (t - 1)) * unit);</span></span>
<span id="L81"><span class="lineNum">      81</span>              :       }</span>
<span id="L82"><span class="lineNum">      82</span>              :       Tensor hidden_state = hidden_state_sample.getSharedDataTensor(</span>
<span id="L83"><span class="lineNum">      83</span> <span class="tlaGNC">         879 :         unit_tensor_dim, (reverse ? max_timestep - 1 - t : t) * unit);</span></span>
<span id="L84"><span class="lineNum">      84</span> <span class="tlaGNC">         879 :       Tensor prev_cell_state;</span></span>
<span id="L85"><span class="lineNum">      85</span> <span class="tlaGNC">         879 :       if (!t) {</span></span>
<span id="L86"><span class="lineNum">      86</span> <span class="tlaGNC">         804 :         prev_cell_state = Tensor(unit, tensor_type);</span></span>
<span id="L87"><span class="lineNum">      87</span> <span class="tlaGNC">         402 :         prev_cell_state.setZero();</span></span>
<span id="L88"><span class="lineNum">      88</span>              :       } else {</span>
<span id="L89"><span class="lineNum">      89</span> <span class="tlaGNC">        1431 :         prev_cell_state = cell_state_sample.getSharedDataTensor(</span></span>
<span id="L90"><span class="lineNum">      90</span> <span class="tlaGNC">         477 :           unit_tensor_dim, (reverse ? (max_timestep - t) : (t - 1)) * unit);</span></span>
<span id="L91"><span class="lineNum">      91</span>              :       }</span>
<span id="L92"><span class="lineNum">      92</span>              :       Tensor cell_state = cell_state_sample.getSharedDataTensor(</span>
<span id="L93"><span class="lineNum">      93</span> <span class="tlaGNC">         879 :         unit_tensor_dim, (reverse ? max_timestep - 1 - t : t) * unit);</span></span>
<span id="L94"><span class="lineNum">      94</span>              :       Tensor ifgo = ifgo_sample.getSharedDataTensor(</span>
<span id="L95"><span class="lineNum">      95</span>              :         num_gate_unit_tensor_dim,</span>
<span id="L96"><span class="lineNum">      96</span> <span class="tlaGNC">         879 :         (reverse ? max_timestep - 1 - t : t) * NUM_GATE * unit);</span></span>
<span id="L97"><span class="lineNum">      97</span>              : </span>
<span id="L98"><span class="lineNum">      98</span> <span class="tlaGNC">         879 :       forwardLSTM(1, unit, disable_bias, integrate_bias, acti_func,</span></span>
<span id="L99"><span class="lineNum">      99</span>              :                   recurrent_acti_func, input, prev_hidden_state,</span>
<span id="L100"><span class="lineNum">     100</span>              :                   prev_cell_state, hidden_state, cell_state, weight_ih,</span>
<span id="L101"><span class="lineNum">     101</span>              :                   weight_hh, bias_h, bias_ih, bias_hh, ifgo);</span>
<span id="L102"><span class="lineNum">     102</span>              : </span>
<span id="L103"><span class="lineNum">     103</span> <span class="tlaGNC">         879 :       if (enable_dropout) {</span></span>
<span id="L104"><span class="lineNum">     104</span> <span class="tlaUNC tlaBgUNC">           0 :         Tensor mask_sample = mask_.getBatchSlice(batch, 1);</span></span>
<span id="L105"><span class="lineNum">     105</span>              :         Tensor mask =</span>
<span id="L106"><span class="lineNum">     106</span> <span class="tlaUNC">           0 :           mask_sample.getSharedDataTensor(unit_tensor_dim, t * unit);</span></span>
<span id="L107"><span class="lineNum">     107</span> <span class="tlaUNC">           0 :         mask.dropout_mask(dropout_rate);</span></span>
<span id="L108"><span class="lineNum">     108</span> <span class="tlaUNC">           0 :         hidden_state.multiply_i(mask);</span></span>
<span id="L109"><span class="lineNum">     109</span> <span class="tlaUNC">           0 :       }</span></span>
<span id="L110"><span class="lineNum">     110</span> <span class="tlaGNC tlaBgGNC">         879 :     }</span></span>
<span id="L111"><span class="lineNum">     111</span> <span class="tlaGNC">         402 :   }</span></span>
<span id="L112"><span class="lineNum">     112</span> <span class="tlaGNC">         189 : }</span></span>
<span id="L113"><span class="lineNum">     113</span>              : </span>
<span id="L114"><span class="lineNum">     114</span> <span class="tlaGNC">         110 : void LSTMLayer::calcGradientBatchFirstLSTM(</span></span>
<span id="L115"><span class="lineNum">     115</span>              :   unsigned int NUM_GATE, const unsigned int batch_size,</span>
<span id="L116"><span class="lineNum">     116</span>              :   const unsigned int feature_size, const bool disable_bias,</span>
<span id="L117"><span class="lineNum">     117</span>              :   const unsigned int unit, const bool integrate_bias, ActiFunc &amp;acti_func,</span>
<span id="L118"><span class="lineNum">     118</span>              :   ActiFunc &amp;recurrent_acti_func, const bool return_sequences,</span>
<span id="L119"><span class="lineNum">     119</span>              :   const bool bidirectional, const bool enable_dropout, const float dropout_rate,</span>
<span id="L120"><span class="lineNum">     120</span>              :   const unsigned int max_timestep, const bool reverse, const Tensor &amp;input_,</span>
<span id="L121"><span class="lineNum">     121</span>              :   const Tensor &amp;incoming_derivative, Tensor &amp;d_weight_ih,</span>
<span id="L122"><span class="lineNum">     122</span>              :   const Tensor &amp;weight_hh, Tensor &amp;d_weight_hh, Tensor &amp;d_bias_h,</span>
<span id="L123"><span class="lineNum">     123</span>              :   Tensor &amp;d_bias_ih, Tensor &amp;d_bias_hh, const Tensor &amp;hidden_state_,</span>
<span id="L124"><span class="lineNum">     124</span>              :   Tensor &amp;d_hidden_state_, const Tensor &amp;cell_state_, Tensor &amp;d_cell_state_,</span>
<span id="L125"><span class="lineNum">     125</span>              :   const Tensor &amp;ifgo_, Tensor &amp;d_ifgo_, const Tensor &amp;mask_) {</span>
<span id="L126"><span class="lineNum">     126</span> <span class="tlaGNC">         110 :   const unsigned int bidirectional_constant = bidirectional ? 2 : 1;</span></span>
<span id="L127"><span class="lineNum">     127</span>              : </span>
<span id="L128"><span class="lineNum">     128</span> <span class="tlaGNC">         110 :   d_weight_ih.setZero();</span></span>
<span id="L129"><span class="lineNum">     129</span> <span class="tlaGNC">         110 :   d_weight_hh.setZero();</span></span>
<span id="L130"><span class="lineNum">     130</span> <span class="tlaGNC">         110 :   if (!disable_bias) {</span></span>
<span id="L131"><span class="lineNum">     131</span> <span class="tlaGNC">         110 :     if (integrate_bias) {</span></span>
<span id="L132"><span class="lineNum">     132</span> <span class="tlaGNC">          83 :       d_bias_h.setZero();</span></span>
<span id="L133"><span class="lineNum">     133</span>              :     } else {</span>
<span id="L134"><span class="lineNum">     134</span> <span class="tlaGNC">          27 :       d_bias_ih.setZero();</span></span>
<span id="L135"><span class="lineNum">     135</span> <span class="tlaGNC">          27 :       d_bias_hh.setZero();</span></span>
<span id="L136"><span class="lineNum">     136</span>              :     }</span>
<span id="L137"><span class="lineNum">     137</span>              :   }</span>
<span id="L138"><span class="lineNum">     138</span>              : </span>
<span id="L139"><span class="lineNum">     139</span> <span class="tlaGNC">         110 :   d_cell_state_.setZero();</span></span>
<span id="L140"><span class="lineNum">     140</span> <span class="tlaGNC">         110 :   d_hidden_state_.setZero();</span></span>
<span id="L141"><span class="lineNum">     141</span>              : </span>
<span id="L142"><span class="lineNum">     142</span> <span class="tlaGNC">         110 :   TensorDim::TensorType tensor_type = weight_hh.getTensorType();</span></span>
<span id="L143"><span class="lineNum">     143</span> <span class="tlaGNC">         110 :   TensorDim unit_tensor_dim({unit}, tensor_type);</span></span>
<span id="L144"><span class="lineNum">     144</span> <span class="tlaGNC">         110 :   TensorDim feature_size_tensor_dim({feature_size}, tensor_type);</span></span>
<span id="L145"><span class="lineNum">     145</span> <span class="tlaGNC">         110 :   TensorDim num_gate_tensor_dim({NUM_GATE * unit}, tensor_type);</span></span>
<span id="L146"><span class="lineNum">     146</span>              : </span>
<span id="L147"><span class="lineNum">     147</span> <span class="tlaGNC">         110 :   if (return_sequences &amp;&amp; !bidirectional &amp;&amp; !reverse) {</span></span>
<span id="L148"><span class="lineNum">     148</span> <span class="tlaGNC">          57 :     if (incoming_derivative.getDataType() == TensorDim::DataType::FP32) {</span></span>
<span id="L149"><span class="lineNum">     149</span> <span class="tlaGNC">          57 :       std::copy(incoming_derivative.getData&lt;float&gt;(),</span></span>
<span id="L150"><span class="lineNum">     150</span> <span class="tlaGNC">          57 :                 incoming_derivative.getData&lt;float&gt;() +</span></span>
<span id="L151"><span class="lineNum">     151</span> <span class="tlaGNC">          57 :                   incoming_derivative.size(),</span></span>
<span id="L152"><span class="lineNum">     152</span>              :                 d_hidden_state_.getData&lt;float&gt;());</span>
<span id="L153"><span class="lineNum">     153</span> <span class="tlaUNC tlaBgUNC">           0 :     } else if (incoming_derivative.getDataType() == TensorDim::DataType::FP16) {</span></span>
<span id="L154"><span class="lineNum">     154</span>              : #ifdef ENABLE_FP16</span>
<span id="L155"><span class="lineNum">     155</span>              :       std::copy(incoming_derivative.getData&lt;_FP16&gt;(),</span>
<span id="L156"><span class="lineNum">     156</span>              :                 incoming_derivative.getData&lt;_FP16&gt;() +</span>
<span id="L157"><span class="lineNum">     157</span>              :                   incoming_derivative.size(),</span>
<span id="L158"><span class="lineNum">     158</span>              :                 d_hidden_state_.getData&lt;_FP16&gt;());</span>
<span id="L159"><span class="lineNum">     159</span>              : #else</span>
<span id="L160"><span class="lineNum">     160</span> <span class="tlaUNC">           0 :       throw std::invalid_argument(&quot;Error: enable-fp16 is not enabled&quot;);</span></span>
<span id="L161"><span class="lineNum">     161</span>              : #endif</span>
<span id="L162"><span class="lineNum">     162</span>              :     }</span>
<span id="L163"><span class="lineNum">     163</span>              :   } else {</span>
<span id="L164"><span class="lineNum">     164</span> <span class="tlaGNC tlaBgGNC">          53 :     unsigned int end_timestep = return_sequences ? max_timestep : 1;</span></span>
<span id="L165"><span class="lineNum">     165</span> <span class="tlaGNC">         157 :     for (unsigned int batch = 0; batch &lt; batch_size; ++batch) {</span></span>
<span id="L166"><span class="lineNum">     166</span> <span class="tlaGNC">         262 :       for (unsigned int timestep = 0; timestep &lt; end_timestep; ++timestep) {</span></span>
<span id="L167"><span class="lineNum">     167</span>              :         Tensor d_hidden_state_sample = d_hidden_state_.getSharedDataTensor(</span>
<span id="L168"><span class="lineNum">     168</span> <span class="tlaGNC">         316 :           unit_tensor_dim, batch * max_timestep * unit +</span></span>
<span id="L169"><span class="lineNum">     169</span> <span class="tlaGNC">         158 :                              (return_sequences ? 0 : max_timestep - 1) * unit +</span></span>
<span id="L170"><span class="lineNum">     170</span> <span class="tlaGNC">         316 :                              timestep * unit);</span></span>
<span id="L171"><span class="lineNum">     171</span>              :         Tensor incoming_derivative_sample =</span>
<span id="L172"><span class="lineNum">     172</span>              :           incoming_derivative.getSharedDataTensor(</span>
<span id="L173"><span class="lineNum">     173</span> <span class="tlaGNC">         158 :             unit_tensor_dim, batch * (return_sequences ? max_timestep : 1) *</span></span>
<span id="L174"><span class="lineNum">     174</span> <span class="tlaGNC">         158 :                                  bidirectional_constant * unit +</span></span>
<span id="L175"><span class="lineNum">     175</span> <span class="tlaGNC">         158 :                                timestep * bidirectional_constant * unit +</span></span>
<span id="L176"><span class="lineNum">     176</span> <span class="tlaGNC">         370 :                                (reverse ? unit : 0));</span></span>
<span id="L177"><span class="lineNum">     177</span> <span class="tlaGNC">         158 :         d_hidden_state_sample.add_i(incoming_derivative_sample);</span></span>
<span id="L178"><span class="lineNum">     178</span> <span class="tlaGNC">         158 :       }</span></span>
<span id="L179"><span class="lineNum">     179</span>              :     }</span>
<span id="L180"><span class="lineNum">     180</span>              :   }</span>
<span id="L181"><span class="lineNum">     181</span>              : </span>
<span id="L182"><span class="lineNum">     182</span> <span class="tlaGNC">         110 :   if (enable_dropout) {</span></span>
<span id="L183"><span class="lineNum">     183</span> <span class="tlaUNC tlaBgUNC">           0 :     d_hidden_state_.multiply_i(mask_);</span></span>
<span id="L184"><span class="lineNum">     184</span>              :   }</span>
<span id="L185"><span class="lineNum">     185</span>              : </span>
<span id="L186"><span class="lineNum">     186</span> <span class="tlaGNC tlaBgGNC">         110 :   auto workers = ParallelBatch(batch_size);</span></span>
<span id="L187"><span class="lineNum">     187</span>              : </span>
<span id="L188"><span class="lineNum">     188</span> <span class="tlaGNC">         110 :   if (workers.getNumWorkers() &gt; 1) {</span></span>
<span id="L189"><span class="lineNum">     189</span>              : </span>
<span id="L190"><span class="lineNum">     190</span> <span class="tlaUNC tlaBgUNC">           0 :     TensorDim weight_ih_d = d_weight_ih.getDim();</span></span>
<span id="L191"><span class="lineNum">     191</span> <span class="tlaUNC">           0 :     TensorDim weight_hh_d = d_weight_hh.getDim();</span></span>
<span id="L192"><span class="lineNum">     192</span>              : </span>
<span id="L193"><span class="lineNum">     193</span> <span class="tlaUNC">           0 :     TensorDim bias_ih_d = d_bias_ih.getDim();</span></span>
<span id="L194"><span class="lineNum">     194</span> <span class="tlaUNC">           0 :     TensorDim bias_hh_d = d_bias_hh.getDim();</span></span>
<span id="L195"><span class="lineNum">     195</span> <span class="tlaUNC">           0 :     TensorDim bias_h_d = d_bias_h.getDim();</span></span>
<span id="L196"><span class="lineNum">     196</span>              : </span>
<span id="L197"><span class="lineNum">     197</span> <span class="tlaUNC">           0 :     weight_ih_d.batch(workers.getNumWorkers());</span></span>
<span id="L198"><span class="lineNum">     198</span> <span class="tlaUNC">           0 :     weight_hh_d.batch(workers.getNumWorkers());</span></span>
<span id="L199"><span class="lineNum">     199</span> <span class="tlaUNC">           0 :     bias_ih_d.batch(workers.getNumWorkers());</span></span>
<span id="L200"><span class="lineNum">     200</span> <span class="tlaUNC">           0 :     bias_hh_d.batch(workers.getNumWorkers());</span></span>
<span id="L201"><span class="lineNum">     201</span> <span class="tlaUNC">           0 :     bias_h_d.batch(workers.getNumWorkers());</span></span>
<span id="L202"><span class="lineNum">     202</span>              : </span>
<span id="L203"><span class="lineNum">     203</span> <span class="tlaUNC">           0 :     Tensor sub_d_weight_ih = Tensor(weight_ih_d);</span></span>
<span id="L204"><span class="lineNum">     204</span> <span class="tlaUNC">           0 :     Tensor sub_d_weight_hh = Tensor(weight_hh_d);</span></span>
<span id="L205"><span class="lineNum">     205</span> <span class="tlaUNC">           0 :     Tensor sub_d_bias_ih = Tensor(bias_ih_d);</span></span>
<span id="L206"><span class="lineNum">     206</span> <span class="tlaUNC">           0 :     Tensor sub_d_bias_hh = Tensor(bias_hh_d);</span></span>
<span id="L207"><span class="lineNum">     207</span> <span class="tlaUNC">           0 :     Tensor sub_d_bias_h = Tensor(bias_h_d);</span></span>
<span id="L208"><span class="lineNum">     208</span>              : </span>
<span id="L209"><span class="lineNum">     209</span> <span class="tlaUNC">           0 :     sub_d_weight_ih.setZero();</span></span>
<span id="L210"><span class="lineNum">     210</span> <span class="tlaUNC">           0 :     sub_d_weight_hh.setZero();</span></span>
<span id="L211"><span class="lineNum">     211</span> <span class="tlaUNC">           0 :     sub_d_bias_ih.setZero();</span></span>
<span id="L212"><span class="lineNum">     212</span> <span class="tlaUNC">           0 :     sub_d_bias_hh.setZero();</span></span>
<span id="L213"><span class="lineNum">     213</span> <span class="tlaUNC">           0 :     sub_d_bias_h.setZero();</span></span>
<span id="L214"><span class="lineNum">     214</span>              : </span>
<span id="L215"><span class="lineNum">     215</span> <span class="tlaUNC">           0 :     auto batch_job = [&amp;](unsigned int s, unsigned int e, unsigned int pid,</span></span>
<span id="L216"><span class="lineNum">     216</span>              :                          void *user_data) {</span>
<span id="L217"><span class="lineNum">     217</span> <span class="tlaUNC">           0 :       for (unsigned int batch = s; batch &lt; e; ++batch) {</span></span>
<span id="L218"><span class="lineNum">     218</span> <span class="tlaUNC">           0 :         const Tensor input_sample = input_.getBatchSlice(batch, 1);</span></span>
<span id="L219"><span class="lineNum">     219</span>              : </span>
<span id="L220"><span class="lineNum">     220</span>              :         const Tensor hidden_state_sample =</span>
<span id="L221"><span class="lineNum">     221</span> <span class="tlaUNC">           0 :           hidden_state_.getBatchSlice(batch, 1);</span></span>
<span id="L222"><span class="lineNum">     222</span> <span class="tlaUNC">           0 :         Tensor d_hidden_state_sample = d_hidden_state_.getBatchSlice(batch, 1);</span></span>
<span id="L223"><span class="lineNum">     223</span> <span class="tlaUNC">           0 :         const Tensor cell_state_sample = cell_state_.getBatchSlice(batch, 1);</span></span>
<span id="L224"><span class="lineNum">     224</span> <span class="tlaUNC">           0 :         Tensor d_cell_state_sample = d_cell_state_.getBatchSlice(batch, 1);</span></span>
<span id="L225"><span class="lineNum">     225</span>              : </span>
<span id="L226"><span class="lineNum">     226</span> <span class="tlaUNC">           0 :         const Tensor ifgo_sample = ifgo_.getBatchSlice(batch, 1);</span></span>
<span id="L227"><span class="lineNum">     227</span> <span class="tlaUNC">           0 :         Tensor d_ifgo_sample = d_ifgo_.getBatchSlice(batch, 1);</span></span>
<span id="L228"><span class="lineNum">     228</span>              : </span>
<span id="L229"><span class="lineNum">     229</span> <span class="tlaUNC">           0 :         Tensor input;</span></span>
<span id="L230"><span class="lineNum">     230</span> <span class="tlaUNC">           0 :         Tensor prev_hidden_state;</span></span>
<span id="L231"><span class="lineNum">     231</span> <span class="tlaUNC">           0 :         Tensor d_prev_hidden_state;</span></span>
<span id="L232"><span class="lineNum">     232</span> <span class="tlaUNC">           0 :         Tensor prev_cell_state;</span></span>
<span id="L233"><span class="lineNum">     233</span> <span class="tlaUNC">           0 :         Tensor d_prev_cell_state;</span></span>
<span id="L234"><span class="lineNum">     234</span> <span class="tlaUNC">           0 :         Tensor d_hidden_state;</span></span>
<span id="L235"><span class="lineNum">     235</span> <span class="tlaUNC">           0 :         Tensor cell_state;</span></span>
<span id="L236"><span class="lineNum">     236</span> <span class="tlaUNC">           0 :         Tensor d_cell_state;</span></span>
<span id="L237"><span class="lineNum">     237</span>              : </span>
<span id="L238"><span class="lineNum">     238</span> <span class="tlaUNC">           0 :         Tensor p_d_weight_ih = sub_d_weight_ih.getBatchSlice(pid, 1);</span></span>
<span id="L239"><span class="lineNum">     239</span> <span class="tlaUNC">           0 :         Tensor p_d_weight_hh = sub_d_weight_hh.getBatchSlice(pid, 1);</span></span>
<span id="L240"><span class="lineNum">     240</span> <span class="tlaUNC">           0 :         Tensor p_d_bias_ih = sub_d_bias_ih.getBatchSlice(pid, 1);</span></span>
<span id="L241"><span class="lineNum">     241</span> <span class="tlaUNC">           0 :         Tensor p_d_bias_hh = sub_d_bias_hh.getBatchSlice(pid, 1);</span></span>
<span id="L242"><span class="lineNum">     242</span> <span class="tlaUNC">           0 :         Tensor p_d_bias_h = sub_d_bias_h.getBatchSlice(pid, 1);</span></span>
<span id="L243"><span class="lineNum">     243</span>              : </span>
<span id="L244"><span class="lineNum">     244</span> <span class="tlaUNC">           0 :         for (int t = max_timestep - 1; t &gt; -1; t--) {</span></span>
<span id="L245"><span class="lineNum">     245</span> <span class="tlaUNC">           0 :           input = input_sample.getSharedDataTensor(</span></span>
<span id="L246"><span class="lineNum">     246</span>              :             feature_size_tensor_dim,</span>
<span id="L247"><span class="lineNum">     247</span> <span class="tlaUNC">           0 :             (reverse ? max_timestep - 1 - t : t) * feature_size);</span></span>
<span id="L248"><span class="lineNum">     248</span>              : </span>
<span id="L249"><span class="lineNum">     249</span> <span class="tlaUNC">           0 :           if (!t) {</span></span>
<span id="L250"><span class="lineNum">     250</span> <span class="tlaUNC">           0 :             prev_hidden_state = Tensor(unit, tensor_type);</span></span>
<span id="L251"><span class="lineNum">     251</span> <span class="tlaUNC">           0 :             prev_hidden_state.setZero();</span></span>
<span id="L252"><span class="lineNum">     252</span> <span class="tlaUNC">           0 :             d_prev_hidden_state = Tensor(unit, tensor_type);</span></span>
<span id="L253"><span class="lineNum">     253</span> <span class="tlaUNC">           0 :             d_prev_hidden_state.setZero();</span></span>
<span id="L254"><span class="lineNum">     254</span>              :           } else {</span>
<span id="L255"><span class="lineNum">     255</span> <span class="tlaUNC">           0 :             prev_hidden_state = hidden_state_sample.getSharedDataTensor(</span></span>
<span id="L256"><span class="lineNum">     256</span> <span class="tlaUNC">           0 :               unit_tensor_dim, (reverse ? (max_timestep - t) : (t - 1)) * unit);</span></span>
<span id="L257"><span class="lineNum">     257</span> <span class="tlaUNC">           0 :             d_prev_hidden_state = d_hidden_state_sample.getSharedDataTensor(</span></span>
<span id="L258"><span class="lineNum">     258</span> <span class="tlaUNC">           0 :               unit_tensor_dim, (reverse ? (max_timestep - t) : (t - 1)) * unit);</span></span>
<span id="L259"><span class="lineNum">     259</span>              :           }</span>
<span id="L260"><span class="lineNum">     260</span> <span class="tlaUNC">           0 :           d_hidden_state = d_hidden_state_sample.getSharedDataTensor(</span></span>
<span id="L261"><span class="lineNum">     261</span> <span class="tlaUNC">           0 :             unit_tensor_dim, (reverse ? max_timestep - 1 - t : t) * unit);</span></span>
<span id="L262"><span class="lineNum">     262</span>              : </span>
<span id="L263"><span class="lineNum">     263</span> <span class="tlaUNC">           0 :           if (!t) {</span></span>
<span id="L264"><span class="lineNum">     264</span> <span class="tlaUNC">           0 :             prev_cell_state = Tensor(unit, tensor_type);</span></span>
<span id="L265"><span class="lineNum">     265</span> <span class="tlaUNC">           0 :             prev_cell_state.setZero();</span></span>
<span id="L266"><span class="lineNum">     266</span> <span class="tlaUNC">           0 :             d_prev_cell_state = Tensor(unit, tensor_type);</span></span>
<span id="L267"><span class="lineNum">     267</span> <span class="tlaUNC">           0 :             d_prev_cell_state.setZero();</span></span>
<span id="L268"><span class="lineNum">     268</span>              :           } else {</span>
<span id="L269"><span class="lineNum">     269</span> <span class="tlaUNC">           0 :             prev_cell_state = cell_state_sample.getSharedDataTensor(</span></span>
<span id="L270"><span class="lineNum">     270</span> <span class="tlaUNC">           0 :               unit_tensor_dim, (reverse ? (max_timestep - t) : (t - 1)) * unit);</span></span>
<span id="L271"><span class="lineNum">     271</span> <span class="tlaUNC">           0 :             d_prev_cell_state = d_cell_state_sample.getSharedDataTensor(</span></span>
<span id="L272"><span class="lineNum">     272</span> <span class="tlaUNC">           0 :               unit_tensor_dim, (reverse ? (max_timestep - t) : (t - 1)) * unit);</span></span>
<span id="L273"><span class="lineNum">     273</span>              :           }</span>
<span id="L274"><span class="lineNum">     274</span> <span class="tlaUNC">           0 :           cell_state = cell_state_sample.getSharedDataTensor(</span></span>
<span id="L275"><span class="lineNum">     275</span> <span class="tlaUNC">           0 :             unit_tensor_dim, (reverse ? max_timestep - 1 - t : t) * unit);</span></span>
<span id="L276"><span class="lineNum">     276</span> <span class="tlaUNC">           0 :           d_cell_state = d_cell_state_sample.getSharedDataTensor(</span></span>
<span id="L277"><span class="lineNum">     277</span> <span class="tlaUNC">           0 :             unit_tensor_dim, (reverse ? max_timestep - 1 - t : t) * unit);</span></span>
<span id="L278"><span class="lineNum">     278</span>              : </span>
<span id="L279"><span class="lineNum">     279</span>              :           Tensor ifgo = ifgo_sample.getSharedDataTensor(</span>
<span id="L280"><span class="lineNum">     280</span>              :             num_gate_tensor_dim,</span>
<span id="L281"><span class="lineNum">     281</span> <span class="tlaUNC">           0 :             (reverse ? max_timestep - 1 - t : t) * NUM_GATE * unit);</span></span>
<span id="L282"><span class="lineNum">     282</span>              :           Tensor d_ifgo = d_ifgo_sample.getSharedDataTensor(</span>
<span id="L283"><span class="lineNum">     283</span>              :             num_gate_tensor_dim,</span>
<span id="L284"><span class="lineNum">     284</span> <span class="tlaUNC">           0 :             (reverse ? max_timestep - 1 - t : t) * NUM_GATE * unit);</span></span>
<span id="L285"><span class="lineNum">     285</span>              : </span>
<span id="L286"><span class="lineNum">     286</span>              :           // Temporary variable for d_prev_hidden_state. d_prev_hidden_state</span>
<span id="L287"><span class="lineNum">     287</span>              :           // already have precalculated values from incomming derivatives</span>
<span id="L288"><span class="lineNum">     288</span>              :           Tensor d_prev_hidden_state_temp =</span>
<span id="L289"><span class="lineNum">     289</span>              :             Tensor(&quot;d_prev_hidden_state_temp&quot;, tensor_type.format,</span>
<span id="L290"><span class="lineNum">     290</span> <span class="tlaUNC">           0 :                    tensor_type.data_type);</span></span>
<span id="L291"><span class="lineNum">     291</span>              : </span>
<span id="L292"><span class="lineNum">     292</span> <span class="tlaUNC">           0 :           calcGradientLSTM(</span></span>
<span id="L293"><span class="lineNum">     293</span> <span class="tlaUNC">           0 :             1, unit, disable_bias, integrate_bias, acti_func,</span></span>
<span id="L294"><span class="lineNum">     294</span>              :             recurrent_acti_func, input, prev_hidden_state,</span>
<span id="L295"><span class="lineNum">     295</span>              :             d_prev_hidden_state_temp, prev_cell_state, d_prev_cell_state,</span>
<span id="L296"><span class="lineNum">     296</span>              :             d_hidden_state, cell_state, d_cell_state, p_d_weight_ih, weight_hh,</span>
<span id="L297"><span class="lineNum">     297</span>              :             p_d_weight_hh, p_d_bias_h, p_d_bias_ih, p_d_bias_hh, ifgo, d_ifgo);</span>
<span id="L298"><span class="lineNum">     298</span>              : </span>
<span id="L299"><span class="lineNum">     299</span> <span class="tlaUNC">           0 :           d_prev_hidden_state.add_i(d_prev_hidden_state_temp);</span></span>
<span id="L300"><span class="lineNum">     300</span> <span class="tlaUNC">           0 :         }</span></span>
<span id="L301"><span class="lineNum">     301</span> <span class="tlaUNC">           0 :       }</span></span>
<span id="L302"><span class="lineNum">     302</span> <span class="tlaUNC">           0 :     };</span></span>
<span id="L303"><span class="lineNum">     303</span>              : </span>
<span id="L304"><span class="lineNum">     304</span> <span class="tlaUNC">           0 :     workers.setCallback(batch_job, nullptr);</span></span>
<span id="L305"><span class="lineNum">     305</span> <span class="tlaUNC">           0 :     workers.run();</span></span>
<span id="L306"><span class="lineNum">     306</span>              : </span>
<span id="L307"><span class="lineNum">     307</span> <span class="tlaUNC">           0 :     for (unsigned int b = 0; b &lt; workers.getNumWorkers(); ++b) {</span></span>
<span id="L308"><span class="lineNum">     308</span>              : </span>
<span id="L309"><span class="lineNum">     309</span> <span class="tlaUNC">           0 :       Tensor p_d_weight_ih = sub_d_weight_ih.getBatchSlice(b, 1);</span></span>
<span id="L310"><span class="lineNum">     310</span> <span class="tlaUNC">           0 :       Tensor p_d_weight_hh = sub_d_weight_hh.getBatchSlice(b, 1);</span></span>
<span id="L311"><span class="lineNum">     311</span> <span class="tlaUNC">           0 :       Tensor p_d_bias_ih = sub_d_bias_ih.getBatchSlice(b, 1);</span></span>
<span id="L312"><span class="lineNum">     312</span> <span class="tlaUNC">           0 :       Tensor p_d_bias_hh = sub_d_bias_hh.getBatchSlice(b, 1);</span></span>
<span id="L313"><span class="lineNum">     313</span> <span class="tlaUNC">           0 :       Tensor p_d_bias_h = sub_d_bias_h.getBatchSlice(b, 1);</span></span>
<span id="L314"><span class="lineNum">     314</span>              : </span>
<span id="L315"><span class="lineNum">     315</span> <span class="tlaUNC">           0 :       d_weight_ih.add_i(p_d_weight_ih);</span></span>
<span id="L316"><span class="lineNum">     316</span> <span class="tlaUNC">           0 :       d_weight_hh.add_i(p_d_weight_hh);</span></span>
<span id="L317"><span class="lineNum">     317</span>              : </span>
<span id="L318"><span class="lineNum">     318</span> <span class="tlaUNC">           0 :       if (!disable_bias) {</span></span>
<span id="L319"><span class="lineNum">     319</span> <span class="tlaUNC">           0 :         if (integrate_bias) {</span></span>
<span id="L320"><span class="lineNum">     320</span> <span class="tlaUNC">           0 :           d_bias_h.add_i(p_d_bias_h);</span></span>
<span id="L321"><span class="lineNum">     321</span>              :         } else {</span>
<span id="L322"><span class="lineNum">     322</span> <span class="tlaUNC">           0 :           d_bias_ih.add_i(p_d_bias_ih);</span></span>
<span id="L323"><span class="lineNum">     323</span> <span class="tlaUNC">           0 :           d_bias_hh.add_i(p_d_bias_hh);</span></span>
<span id="L324"><span class="lineNum">     324</span>              :         }</span>
<span id="L325"><span class="lineNum">     325</span>              :       }</span>
<span id="L326"><span class="lineNum">     326</span> <span class="tlaUNC">           0 :     }</span></span>
<span id="L327"><span class="lineNum">     327</span>              : </span>
<span id="L328"><span class="lineNum">     328</span> <span class="tlaUNC">           0 :   } else {</span></span>
<span id="L329"><span class="lineNum">     329</span> <span class="tlaGNC tlaBgGNC">         319 :     for (unsigned int batch = 0; batch &lt; batch_size; ++batch) {</span></span>
<span id="L330"><span class="lineNum">     330</span> <span class="tlaGNC">         209 :       const Tensor input_sample = input_.getBatchSlice(batch, 1);</span></span>
<span id="L331"><span class="lineNum">     331</span>              : </span>
<span id="L332"><span class="lineNum">     332</span> <span class="tlaGNC">         209 :       const Tensor hidden_state_sample = hidden_state_.getBatchSlice(batch, 1);</span></span>
<span id="L333"><span class="lineNum">     333</span> <span class="tlaGNC">         209 :       Tensor d_hidden_state_sample = d_hidden_state_.getBatchSlice(batch, 1);</span></span>
<span id="L334"><span class="lineNum">     334</span> <span class="tlaGNC">         209 :       const Tensor cell_state_sample = cell_state_.getBatchSlice(batch, 1);</span></span>
<span id="L335"><span class="lineNum">     335</span> <span class="tlaGNC">         209 :       Tensor d_cell_state_sample = d_cell_state_.getBatchSlice(batch, 1);</span></span>
<span id="L336"><span class="lineNum">     336</span>              : </span>
<span id="L337"><span class="lineNum">     337</span> <span class="tlaGNC">         209 :       const Tensor ifgo_sample = ifgo_.getBatchSlice(batch, 1);</span></span>
<span id="L338"><span class="lineNum">     338</span> <span class="tlaGNC">         209 :       Tensor d_ifgo_sample = d_ifgo_.getBatchSlice(batch, 1);</span></span>
<span id="L339"><span class="lineNum">     339</span>              : </span>
<span id="L340"><span class="lineNum">     340</span> <span class="tlaGNC">         209 :       Tensor input;</span></span>
<span id="L341"><span class="lineNum">     341</span> <span class="tlaGNC">         209 :       Tensor prev_hidden_state;</span></span>
<span id="L342"><span class="lineNum">     342</span> <span class="tlaGNC">         209 :       Tensor d_prev_hidden_state;</span></span>
<span id="L343"><span class="lineNum">     343</span> <span class="tlaGNC">         209 :       Tensor prev_cell_state;</span></span>
<span id="L344"><span class="lineNum">     344</span> <span class="tlaGNC">         209 :       Tensor d_prev_cell_state;</span></span>
<span id="L345"><span class="lineNum">     345</span> <span class="tlaGNC">         209 :       Tensor d_hidden_state;</span></span>
<span id="L346"><span class="lineNum">     346</span> <span class="tlaGNC">         209 :       Tensor cell_state;</span></span>
<span id="L347"><span class="lineNum">     347</span> <span class="tlaGNC">         209 :       Tensor d_cell_state;</span></span>
<span id="L348"><span class="lineNum">     348</span>              : </span>
<span id="L349"><span class="lineNum">     349</span> <span class="tlaGNC">         634 :       for (int t = max_timestep - 1; t &gt; -1; t--) {</span></span>
<span id="L350"><span class="lineNum">     350</span> <span class="tlaGNC">         850 :         input = input_sample.getSharedDataTensor(</span></span>
<span id="L351"><span class="lineNum">     351</span>              :           feature_size_tensor_dim,</span>
<span id="L352"><span class="lineNum">     352</span> <span class="tlaGNC">         425 :           (reverse ? max_timestep - 1 - t : t) * feature_size);</span></span>
<span id="L353"><span class="lineNum">     353</span>              : </span>
<span id="L354"><span class="lineNum">     354</span> <span class="tlaGNC">         425 :         if (!t) {</span></span>
<span id="L355"><span class="lineNum">     355</span> <span class="tlaGNC">         627 :           prev_hidden_state = Tensor(unit, tensor_type);</span></span>
<span id="L356"><span class="lineNum">     356</span> <span class="tlaGNC">         209 :           prev_hidden_state.setZero();</span></span>
<span id="L357"><span class="lineNum">     357</span> <span class="tlaGNC">         627 :           d_prev_hidden_state = Tensor(unit, tensor_type);</span></span>
<span id="L358"><span class="lineNum">     358</span> <span class="tlaGNC">         209 :           d_prev_hidden_state.setZero();</span></span>
<span id="L359"><span class="lineNum">     359</span>              :         } else {</span>
<span id="L360"><span class="lineNum">     360</span> <span class="tlaGNC">         432 :           prev_hidden_state = hidden_state_sample.getSharedDataTensor(</span></span>
<span id="L361"><span class="lineNum">     361</span> <span class="tlaGNC">         216 :             unit_tensor_dim, (reverse ? (max_timestep - t) : (t - 1)) * unit);</span></span>
<span id="L362"><span class="lineNum">     362</span> <span class="tlaGNC">         648 :           d_prev_hidden_state = d_hidden_state_sample.getSharedDataTensor(</span></span>
<span id="L363"><span class="lineNum">     363</span> <span class="tlaGNC">         216 :             unit_tensor_dim, (reverse ? (max_timestep - t) : (t - 1)) * unit);</span></span>
<span id="L364"><span class="lineNum">     364</span>              :         }</span>
<span id="L365"><span class="lineNum">     365</span> <span class="tlaGNC">         850 :         d_hidden_state = d_hidden_state_sample.getSharedDataTensor(</span></span>
<span id="L366"><span class="lineNum">     366</span> <span class="tlaGNC">         425 :           unit_tensor_dim, (reverse ? max_timestep - 1 - t : t) * unit);</span></span>
<span id="L367"><span class="lineNum">     367</span>              : </span>
<span id="L368"><span class="lineNum">     368</span> <span class="tlaGNC">         425 :         if (!t) {</span></span>
<span id="L369"><span class="lineNum">     369</span> <span class="tlaGNC">         627 :           prev_cell_state = Tensor(unit, tensor_type);</span></span>
<span id="L370"><span class="lineNum">     370</span> <span class="tlaGNC">         209 :           prev_cell_state.setZero();</span></span>
<span id="L371"><span class="lineNum">     371</span> <span class="tlaGNC">         627 :           d_prev_cell_state = Tensor(unit, tensor_type);</span></span>
<span id="L372"><span class="lineNum">     372</span> <span class="tlaGNC">         209 :           d_prev_cell_state.setZero();</span></span>
<span id="L373"><span class="lineNum">     373</span>              :         } else {</span>
<span id="L374"><span class="lineNum">     374</span> <span class="tlaGNC">         432 :           prev_cell_state = cell_state_sample.getSharedDataTensor(</span></span>
<span id="L375"><span class="lineNum">     375</span> <span class="tlaGNC">         216 :             unit_tensor_dim, (reverse ? (max_timestep - t) : (t - 1)) * unit);</span></span>
<span id="L376"><span class="lineNum">     376</span> <span class="tlaGNC">         648 :           d_prev_cell_state = d_cell_state_sample.getSharedDataTensor(</span></span>
<span id="L377"><span class="lineNum">     377</span> <span class="tlaGNC">         216 :             unit_tensor_dim, (reverse ? (max_timestep - t) : (t - 1)) * unit);</span></span>
<span id="L378"><span class="lineNum">     378</span>              :         }</span>
<span id="L379"><span class="lineNum">     379</span> <span class="tlaGNC">         850 :         cell_state = cell_state_sample.getSharedDataTensor(</span></span>
<span id="L380"><span class="lineNum">     380</span> <span class="tlaGNC">         425 :           unit_tensor_dim, (reverse ? max_timestep - 1 - t : t) * unit);</span></span>
<span id="L381"><span class="lineNum">     381</span> <span class="tlaGNC">         850 :         d_cell_state = d_cell_state_sample.getSharedDataTensor(</span></span>
<span id="L382"><span class="lineNum">     382</span> <span class="tlaGNC">         425 :           unit_tensor_dim, (reverse ? max_timestep - 1 - t : t) * unit);</span></span>
<span id="L383"><span class="lineNum">     383</span>              : </span>
<span id="L384"><span class="lineNum">     384</span>              :         Tensor ifgo = ifgo_sample.getSharedDataTensor(</span>
<span id="L385"><span class="lineNum">     385</span>              :           num_gate_tensor_dim,</span>
<span id="L386"><span class="lineNum">     386</span> <span class="tlaGNC">         425 :           (reverse ? max_timestep - 1 - t : t) * NUM_GATE * unit);</span></span>
<span id="L387"><span class="lineNum">     387</span>              :         Tensor d_ifgo = d_ifgo_sample.getSharedDataTensor(</span>
<span id="L388"><span class="lineNum">     388</span>              :           num_gate_tensor_dim,</span>
<span id="L389"><span class="lineNum">     389</span> <span class="tlaGNC">         425 :           (reverse ? max_timestep - 1 - t : t) * NUM_GATE * unit);</span></span>
<span id="L390"><span class="lineNum">     390</span>              : </span>
<span id="L391"><span class="lineNum">     391</span>              :         // Temporary variable for d_prev_hidden_state. d_prev_hidden_state</span>
<span id="L392"><span class="lineNum">     392</span>              :         // already have precalculated values from incomming derivatives</span>
<span id="L393"><span class="lineNum">     393</span>              :         Tensor d_prev_hidden_state_temp =</span>
<span id="L394"><span class="lineNum">     394</span>              :           Tensor(&quot;d_prev_hidden_state_temp&quot;, tensor_type.format,</span>
<span id="L395"><span class="lineNum">     395</span> <span class="tlaGNC">         425 :                  tensor_type.data_type);</span></span>
<span id="L396"><span class="lineNum">     396</span>              : </span>
<span id="L397"><span class="lineNum">     397</span> <span class="tlaGNC">         425 :         calcGradientLSTM(1, unit, disable_bias, integrate_bias, acti_func,</span></span>
<span id="L398"><span class="lineNum">     398</span>              :                          recurrent_acti_func, input, prev_hidden_state,</span>
<span id="L399"><span class="lineNum">     399</span>              :                          d_prev_hidden_state_temp, prev_cell_state,</span>
<span id="L400"><span class="lineNum">     400</span>              :                          d_prev_cell_state, d_hidden_state, cell_state,</span>
<span id="L401"><span class="lineNum">     401</span>              :                          d_cell_state, d_weight_ih, weight_hh, d_weight_hh,</span>
<span id="L402"><span class="lineNum">     402</span>              :                          d_bias_h, d_bias_ih, d_bias_hh, ifgo, d_ifgo);</span>
<span id="L403"><span class="lineNum">     403</span> <span class="tlaGNC">         425 :         d_prev_hidden_state.add_i(d_prev_hidden_state_temp);</span></span>
<span id="L404"><span class="lineNum">     404</span> <span class="tlaGNC">         425 :       }</span></span>
<span id="L405"><span class="lineNum">     405</span> <span class="tlaGNC">         209 :     }</span></span>
<span id="L406"><span class="lineNum">     406</span>              :   }</span>
<span id="L407"><span class="lineNum">     407</span> <span class="tlaGNC">         110 : }</span></span>
<span id="L408"><span class="lineNum">     408</span>              : </span>
<span id="L409"><span class="lineNum">     409</span> <span class="tlaGNC">          76 : LSTMLayer::LSTMLayer() :</span></span>
<span id="L410"><span class="lineNum">     410</span>              :   LSTMCore(),</span>
<span id="L411"><span class="lineNum">     411</span> <span class="tlaGNC">          76 :   lstm_props(props::ReturnSequences(), props::Bidirectional(),</span></span>
<span id="L412"><span class="lineNum">     412</span> <span class="tlaGNC">         152 :              props::DropOutRate(), props::MaxTimestep()) {</span></span>
<span id="L413"><span class="lineNum">     413</span>              :   wt_idx.fill(std::numeric_limits&lt;unsigned&gt;::max());</span>
<span id="L414"><span class="lineNum">     414</span> <span class="tlaGNC">          76 : }</span></span>
<span id="L415"><span class="lineNum">     415</span>              : </span>
<span id="L416"><span class="lineNum">     416</span> <span class="tlaGNC">          62 : void LSTMLayer::finalize(InitLayerContext &amp;context) {</span></span>
<span id="L417"><span class="lineNum">     417</span>              :   const Initializer weight_initializer =</span>
<span id="L418"><span class="lineNum">     418</span> <span class="tlaGNC">          62 :     std::get&lt;props::WeightInitializer&gt;(*layer_impl_props).get();</span></span>
<span id="L419"><span class="lineNum">     419</span>              :   const Initializer bias_initializer =</span>
<span id="L420"><span class="lineNum">     420</span> <span class="tlaGNC">          62 :     std::get&lt;props::BiasInitializer&gt;(*layer_impl_props).get();</span></span>
<span id="L421"><span class="lineNum">     421</span>              :   const nntrainer::WeightRegularizer weight_regularizer =</span>
<span id="L422"><span class="lineNum">     422</span> <span class="tlaGNC">          62 :     std::get&lt;props::WeightRegularizer&gt;(*layer_impl_props).get();</span></span>
<span id="L423"><span class="lineNum">     423</span>              :   const float weight_regularizer_constant =</span>
<span id="L424"><span class="lineNum">     424</span> <span class="tlaGNC">          62 :     std::get&lt;props::WeightRegularizerConstant&gt;(*layer_impl_props).get();</span></span>
<span id="L425"><span class="lineNum">     425</span>              :   auto &amp;weight_decay = std::get&lt;props::WeightDecay&gt;(*layer_impl_props);</span>
<span id="L426"><span class="lineNum">     426</span>              :   auto &amp;bias_decay = std::get&lt;props::BiasDecay&gt;(*layer_impl_props);</span>
<span id="L427"><span class="lineNum">     427</span>              :   const bool disable_bias =</span>
<span id="L428"><span class="lineNum">     428</span> <span class="tlaGNC">          62 :     std::get&lt;props::DisableBias&gt;(*layer_impl_props).get();</span></span>
<span id="L429"><span class="lineNum">     429</span>              : </span>
<span id="L430"><span class="lineNum">     430</span> <span class="tlaGNC">          62 :   NNTR_THROW_IF(std::get&lt;props::Unit&gt;(lstmcore_props).empty(),</span></span>
<span id="L431"><span class="lineNum">     431</span>              :                 std::invalid_argument)</span>
<span id="L432"><span class="lineNum">     432</span>              :     &lt;&lt; &quot;unit property missing for lstm layer&quot;;</span>
<span id="L433"><span class="lineNum">     433</span> <span class="tlaGNC">          62 :   const unsigned int unit = std::get&lt;props::Unit&gt;(lstmcore_props).get();</span></span>
<span id="L434"><span class="lineNum">     434</span>              :   const bool integrate_bias =</span>
<span id="L435"><span class="lineNum">     435</span> <span class="tlaGNC">          62 :     std::get&lt;props::IntegrateBias&gt;(lstmcore_props).get();</span></span>
<span id="L436"><span class="lineNum">     436</span>              :   const ActivationType hidden_state_activation_type =</span>
<span id="L437"><span class="lineNum">     437</span> <span class="tlaGNC">          62 :     std::get&lt;props::HiddenStateActivation&gt;(lstmcore_props).get();</span></span>
<span id="L438"><span class="lineNum">     438</span>              :   const ActivationType recurrent_activation_type =</span>
<span id="L439"><span class="lineNum">     439</span> <span class="tlaGNC">          62 :     std::get&lt;props::RecurrentActivation&gt;(lstmcore_props).get();</span></span>
<span id="L440"><span class="lineNum">     440</span>              : </span>
<span id="L441"><span class="lineNum">     441</span>              :   const bool return_sequences =</span>
<span id="L442"><span class="lineNum">     442</span> <span class="tlaGNC">          62 :     std::get&lt;props::ReturnSequences&gt;(lstm_props).get();</span></span>
<span id="L443"><span class="lineNum">     443</span> <span class="tlaGNC">          62 :   const bool bidirectional = std::get&lt;props::Bidirectional&gt;(lstm_props).get();</span></span>
<span id="L444"><span class="lineNum">     444</span> <span class="tlaGNC">          62 :   const float dropout_rate = std::get&lt;props::DropOutRate&gt;(lstm_props).get();</span></span>
<span id="L445"><span class="lineNum">     445</span>              : </span>
<span id="L446"><span class="lineNum">     446</span> <span class="tlaGNC">          62 :   if (context.getNumInputs() != 1) {</span></span>
<span id="L447"><span class="lineNum">     447</span> <span class="tlaUNC tlaBgUNC">           0 :     throw std::invalid_argument(&quot;LSTM layer takes only one input&quot;);</span></span>
<span id="L448"><span class="lineNum">     448</span>              :   }</span>
<span id="L449"><span class="lineNum">     449</span>              : </span>
<span id="L450"><span class="lineNum">     450</span>              :   // input_dim = [ batch_size, 1, time_iteration, feature_size ]</span>
<span id="L451"><span class="lineNum">     451</span>              :   const TensorDim &amp;input_dim = context.getInputDimensions()[SINGLE_INOUT_IDX];</span>
<span id="L452"><span class="lineNum">     452</span> <span class="tlaGNC tlaBgGNC">          62 :   if (input_dim.channel() != 1) {</span></span>
<span id="L453"><span class="lineNum">     453</span>              :     throw std::invalid_argument(</span>
<span id="L454"><span class="lineNum">     454</span>              :       &quot;Input must be single channel dimension for LSTM (shape should be &quot;</span>
<span id="L455"><span class="lineNum">     455</span> <span class="tlaUNC tlaBgUNC">           0 :       &quot;[batch_size, 1, time_iteration, feature_size])&quot;);</span></span>
<span id="L456"><span class="lineNum">     456</span>              :   }</span>
<span id="L457"><span class="lineNum">     457</span> <span class="tlaGNC tlaBgGNC">          62 :   const unsigned int batch_size = input_dim.batch();</span></span>
<span id="L458"><span class="lineNum">     458</span> <span class="tlaGNC">          62 :   unsigned int max_timestep = input_dim.height();</span></span>
<span id="L459"><span class="lineNum">     459</span> <span class="tlaGNC">          62 :   if (!std::get&lt;props::MaxTimestep&gt;(lstm_props).empty())</span></span>
<span id="L460"><span class="lineNum">     460</span> <span class="tlaGNC">          26 :     max_timestep =</span></span>
<span id="L461"><span class="lineNum">     461</span> <span class="tlaGNC">          52 :       std::max(max_timestep, std::get&lt;props::MaxTimestep&gt;(lstm_props).get());</span></span>
<span id="L462"><span class="lineNum">     462</span> <span class="tlaGNC">          62 :   NNTR_THROW_IF(max_timestep &lt; 1, std::runtime_error)</span></span>
<span id="L463"><span class="lineNum">     463</span>              :     &lt;&lt; &quot;max timestep must be greator than 0 in lstm layer.&quot;;</span>
<span id="L464"><span class="lineNum">     464</span> <span class="tlaGNC">          62 :   std::get&lt;props::MaxTimestep&gt;(lstm_props).set(max_timestep);</span></span>
<span id="L465"><span class="lineNum">     465</span> <span class="tlaGNC">          62 :   const unsigned int feature_size = input_dim.width();</span></span>
<span id="L466"><span class="lineNum">     466</span>              : </span>
<span id="L467"><span class="lineNum">     467</span>              :   // output_dim = [ batch_size, 1, return_sequences ? time_iteration : 1,</span>
<span id="L468"><span class="lineNum">     468</span>              :   // bidirectional ? 2 * unit : unit ]</span>
<span id="L469"><span class="lineNum">     469</span>              :   TensorDim::TensorType activation_tensor_type = {</span>
<span id="L470"><span class="lineNum">     470</span>              :     context.getFormat(), context.getActivationDataType()};</span>
<span id="L471"><span class="lineNum">     471</span>              : </span>
<span id="L472"><span class="lineNum">     472</span>              :   TensorDim::TensorType weight_tensor_type = {context.getFormat(),</span>
<span id="L473"><span class="lineNum">     473</span>              :                                               context.getWeightDataType()};</span>
<span id="L474"><span class="lineNum">     474</span> <span class="tlaGNC">          44 :   const TensorDim output_dim(batch_size, 1, return_sequences ? max_timestep : 1,</span></span>
<span id="L475"><span class="lineNum">     475</span> <span class="tlaGNC">          12 :                              bidirectional ? 2 * unit : unit,</span></span>
<span id="L476"><span class="lineNum">     476</span> <span class="tlaGNC">          62 :                              activation_tensor_type);</span></span>
<span id="L477"><span class="lineNum">     477</span> <span class="tlaGNC">          62 :   context.setOutputDimensions({output_dim});</span></span>
<span id="L478"><span class="lineNum">     478</span>              : </span>
<span id="L479"><span class="lineNum">     479</span>              :   // weight_initializer can be set seperately. weight_ih initializer,</span>
<span id="L480"><span class="lineNum">     480</span>              :   // weight_hh initializer kernel initializer &amp; recurrent_initializer in</span>
<span id="L481"><span class="lineNum">     481</span>              :   // keras for now, it is set same way.</span>
<span id="L482"><span class="lineNum">     482</span>              : </span>
<span id="L483"><span class="lineNum">     483</span>              :   // weight_ih ( input to hidden ) : [ 1, 1, feature_size, NUM_GATE * unit ]</span>
<span id="L484"><span class="lineNum">     484</span>              :   // -&gt; i, f, g, o</span>
<span id="L485"><span class="lineNum">     485</span> <span class="tlaGNC">          62 :   const TensorDim weight_ih_dim({feature_size, NUM_GATE * unit},</span></span>
<span id="L486"><span class="lineNum">     486</span> <span class="tlaGNC">          62 :                                 weight_tensor_type);</span></span>
<span id="L487"><span class="lineNum">     487</span> <span class="tlaGNC">          62 :   wt_idx[LSTMParams::weight_ih] = context.requestWeight(</span></span>
<span id="L488"><span class="lineNum">     488</span>              :     weight_ih_dim, weight_initializer, weight_regularizer,</span>
<span id="L489"><span class="lineNum">     489</span>              :     weight_regularizer_constant, weight_decay, &quot;weight_ih&quot;, true);</span>
<span id="L490"><span class="lineNum">     490</span>              :   // weight_hh ( hidden to hidden ) : [ 1, 1, unit, NUM_GATE * unit ] -&gt; i,</span>
<span id="L491"><span class="lineNum">     491</span>              :   // f, g, o</span>
<span id="L492"><span class="lineNum">     492</span> <span class="tlaGNC">          62 :   const TensorDim weight_hh_dim({unit, NUM_GATE * unit}, weight_tensor_type);</span></span>
<span id="L493"><span class="lineNum">     493</span> <span class="tlaGNC">         124 :   wt_idx[LSTMParams::weight_hh] = context.requestWeight(</span></span>
<span id="L494"><span class="lineNum">     494</span>              :     weight_hh_dim, weight_initializer, weight_regularizer,</span>
<span id="L495"><span class="lineNum">     495</span>              :     weight_regularizer_constant, weight_decay, &quot;weight_hh&quot;, true);</span>
<span id="L496"><span class="lineNum">     496</span> <span class="tlaGNC">          62 :   if (!disable_bias) {</span></span>
<span id="L497"><span class="lineNum">     497</span> <span class="tlaGNC">          62 :     if (integrate_bias) {</span></span>
<span id="L498"><span class="lineNum">     498</span>              :       // bias_h ( input bias, hidden bias are integrate to 1 bias ) : [ 1,</span>
<span id="L499"><span class="lineNum">     499</span>              :       // 1, 1, NUM_GATE * unit ] -&gt; i, f, g, o</span>
<span id="L500"><span class="lineNum">     500</span> <span class="tlaGNC">          34 :       const TensorDim bias_h_dim({NUM_GATE * unit}, weight_tensor_type);</span></span>
<span id="L501"><span class="lineNum">     501</span> <span class="tlaGNC">          34 :       wt_idx[LSTMParams::bias_h] = context.requestWeight(</span></span>
<span id="L502"><span class="lineNum">     502</span>              :         bias_h_dim, bias_initializer, WeightRegularizer::NONE, 1.0f, bias_decay,</span>
<span id="L503"><span class="lineNum">     503</span>              :         &quot;bias_h&quot;, true);</span>
<span id="L504"><span class="lineNum">     504</span>              :     } else {</span>
<span id="L505"><span class="lineNum">     505</span>              :       // bias_ih ( input bias ) : [ 1, 1, 1, NUM_GATE * unit ] -&gt; i, f, g, o</span>
<span id="L506"><span class="lineNum">     506</span> <span class="tlaGNC">          28 :       const TensorDim bias_ih_dim({NUM_GATE * unit}, weight_tensor_type);</span></span>
<span id="L507"><span class="lineNum">     507</span> <span class="tlaGNC">          28 :       wt_idx[LSTMParams::bias_ih] = context.requestWeight(</span></span>
<span id="L508"><span class="lineNum">     508</span>              :         bias_ih_dim, bias_initializer, WeightRegularizer::NONE, 1.0f,</span>
<span id="L509"><span class="lineNum">     509</span>              :         bias_decay, &quot;bias_ih&quot;, true);</span>
<span id="L510"><span class="lineNum">     510</span>              :       // bias_hh ( hidden bias ) : [ 1, 1, 1, NUM_GATE * unit ] -&gt; i, f, g, o</span>
<span id="L511"><span class="lineNum">     511</span> <span class="tlaGNC">          56 :       wt_idx[LSTMParams::bias_hh] = context.requestWeight(</span></span>
<span id="L512"><span class="lineNum">     512</span>              :         bias_ih_dim, bias_initializer, WeightRegularizer::NONE, 1.0f,</span>
<span id="L513"><span class="lineNum">     513</span>              :         bias_decay, &quot;bias_hh&quot;, true);</span>
<span id="L514"><span class="lineNum">     514</span>              :     }</span>
<span id="L515"><span class="lineNum">     515</span>              :   }</span>
<span id="L516"><span class="lineNum">     516</span>              : </span>
<span id="L517"><span class="lineNum">     517</span>              :   // hidden_state_dim : [ batch_size, 1, max_timestep, unit ]</span>
<span id="L518"><span class="lineNum">     518</span>              :   const TensorDim hidden_state_dim(batch_size, 1, max_timestep, unit,</span>
<span id="L519"><span class="lineNum">     519</span> <span class="tlaGNC">          62 :                                    activation_tensor_type);</span></span>
<span id="L520"><span class="lineNum">     520</span>              : </span>
<span id="L521"><span class="lineNum">     521</span> <span class="tlaGNC">          62 :   wt_idx[LSTMParams::hidden_state] =</span></span>
<span id="L522"><span class="lineNum">     522</span> <span class="tlaGNC">         124 :     context.requestTensor(hidden_state_dim, &quot;hidden_state&quot;, Initializer::NONE,</span></span>
<span id="L523"><span class="lineNum">     523</span>              :                           true, TensorLifespan::ITERATION_LIFESPAN);</span>
<span id="L524"><span class="lineNum">     524</span>              :   // cell_state_dim : [ batch_size, 1, max_timestep, unit ]</span>
<span id="L525"><span class="lineNum">     525</span>              :   const TensorDim cell_state_dim(batch_size, 1, max_timestep, unit,</span>
<span id="L526"><span class="lineNum">     526</span> <span class="tlaGNC">          62 :                                  activation_tensor_type);</span></span>
<span id="L527"><span class="lineNum">     527</span>              : </span>
<span id="L528"><span class="lineNum">     528</span> <span class="tlaGNC">          62 :   wt_idx[LSTMParams::cell_state] =</span></span>
<span id="L529"><span class="lineNum">     529</span> <span class="tlaGNC">         124 :     context.requestTensor(cell_state_dim, &quot;cell_state&quot;, Initializer::NONE, true,</span></span>
<span id="L530"><span class="lineNum">     530</span>              :                           TensorLifespan::ITERATION_LIFESPAN);</span>
<span id="L531"><span class="lineNum">     531</span>              : </span>
<span id="L532"><span class="lineNum">     532</span>              :   // ifgo_dim : [ batch_size, 1, max_timestep, NUM_GATE * unit ]</span>
<span id="L533"><span class="lineNum">     533</span>              :   const TensorDim ifgo_dim(batch_size, 1, max_timestep, NUM_GATE * unit,</span>
<span id="L534"><span class="lineNum">     534</span> <span class="tlaGNC">          62 :                            activation_tensor_type);</span></span>
<span id="L535"><span class="lineNum">     535</span>              : </span>
<span id="L536"><span class="lineNum">     536</span> <span class="tlaGNC">          62 :   wt_idx[LSTMParams::ifgo] =</span></span>
<span id="L537"><span class="lineNum">     537</span> <span class="tlaGNC">          62 :     context.requestTensor(ifgo_dim, &quot;ifgo&quot;, Initializer::NONE, true,</span></span>
<span id="L538"><span class="lineNum">     538</span>              :                           TensorLifespan::ITERATION_LIFESPAN);</span>
<span id="L539"><span class="lineNum">     539</span>              : </span>
<span id="L540"><span class="lineNum">     540</span> <span class="tlaGNC">          62 :   if (bidirectional) {</span></span>
<span id="L541"><span class="lineNum">     541</span>              :     // weight_initializer can be set seperately. weight_ih initializer,</span>
<span id="L542"><span class="lineNum">     542</span>              :     // weight_hh initializer kernel initializer &amp; recurrent_initializer in</span>
<span id="L543"><span class="lineNum">     543</span>              :     // keras for now, it is set same way.</span>
<span id="L544"><span class="lineNum">     544</span>              : </span>
<span id="L545"><span class="lineNum">     545</span>              :     // reverse_weight_ih ( input to hidden ) : [ 1, 1, feature_size,</span>
<span id="L546"><span class="lineNum">     546</span>              :     // NUM_GATE * unit ] -&gt; i, f, g, o</span>
<span id="L547"><span class="lineNum">     547</span>              :     const TensorDim reverse_weight_ih_dim({feature_size, NUM_GATE * unit},</span>
<span id="L548"><span class="lineNum">     548</span> <span class="tlaGNC">          12 :                                           weight_tensor_type);</span></span>
<span id="L549"><span class="lineNum">     549</span> <span class="tlaGNC">          24 :     wt_idx[LSTMParams::reverse_weight_ih] = context.requestWeight(</span></span>
<span id="L550"><span class="lineNum">     550</span>              :       reverse_weight_ih_dim, weight_initializer, weight_regularizer,</span>
<span id="L551"><span class="lineNum">     551</span>              :       weight_regularizer_constant, weight_decay, &quot;reverse_weight_ih&quot;, true);</span>
<span id="L552"><span class="lineNum">     552</span>              :     // reverse_weight_hh ( hidden to hidden ) : [ 1, 1, unit, NUM_GATE *</span>
<span id="L553"><span class="lineNum">     553</span>              :     // unit ]</span>
<span id="L554"><span class="lineNum">     554</span>              :     // -&gt; i, f, g, o</span>
<span id="L555"><span class="lineNum">     555</span>              :     const TensorDim reverse_weight_hh_dim({unit, NUM_GATE * unit},</span>
<span id="L556"><span class="lineNum">     556</span> <span class="tlaGNC">          12 :                                           weight_tensor_type);</span></span>
<span id="L557"><span class="lineNum">     557</span> <span class="tlaGNC">          24 :     wt_idx[LSTMParams::reverse_weight_hh] = context.requestWeight(</span></span>
<span id="L558"><span class="lineNum">     558</span>              :       reverse_weight_hh_dim, weight_initializer, weight_regularizer,</span>
<span id="L559"><span class="lineNum">     559</span>              :       weight_regularizer_constant, weight_decay, &quot;reverse_weight_hh&quot;, true);</span>
<span id="L560"><span class="lineNum">     560</span> <span class="tlaGNC">          12 :     if (!disable_bias) {</span></span>
<span id="L561"><span class="lineNum">     561</span> <span class="tlaGNC">          12 :       if (integrate_bias) {</span></span>
<span id="L562"><span class="lineNum">     562</span>              :         // reverse_bias_h ( input bias, hidden bias are integrate to 1 bias</span>
<span id="L563"><span class="lineNum">     563</span>              :         // ) : [ 1, 1, 1, NUM_GATE * unit ] -&gt; i, f, g, o</span>
<span id="L564"><span class="lineNum">     564</span>              :         const TensorDim reverse_bias_h_dim({NUM_GATE * unit},</span>
<span id="L565"><span class="lineNum">     565</span> <span class="tlaUNC tlaBgUNC">           0 :                                            weight_tensor_type);</span></span>
<span id="L566"><span class="lineNum">     566</span> <span class="tlaUNC">           0 :         wt_idx[LSTMParams::reverse_bias_h] = context.requestWeight(</span></span>
<span id="L567"><span class="lineNum">     567</span>              :           reverse_bias_h_dim, bias_initializer, WeightRegularizer::NONE, 1.0f,</span>
<span id="L568"><span class="lineNum">     568</span>              :           bias_decay, &quot;reverse_bias_h&quot;, true);</span>
<span id="L569"><span class="lineNum">     569</span>              :       } else {</span>
<span id="L570"><span class="lineNum">     570</span>              :         // reverse_bias_ih ( input bias ) : [ 1, 1, 1, NUM_GATE * unit ] -&gt;</span>
<span id="L571"><span class="lineNum">     571</span>              :         // i, f, g, o</span>
<span id="L572"><span class="lineNum">     572</span>              :         const TensorDim reverse_bias_ih_dim({NUM_GATE * unit},</span>
<span id="L573"><span class="lineNum">     573</span> <span class="tlaGNC tlaBgGNC">          12 :                                             weight_tensor_type);</span></span>
<span id="L574"><span class="lineNum">     574</span> <span class="tlaGNC">          12 :         wt_idx[LSTMParams::reverse_bias_ih] = context.requestWeight(</span></span>
<span id="L575"><span class="lineNum">     575</span>              :           reverse_bias_ih_dim, bias_initializer, WeightRegularizer::NONE, 1.0f,</span>
<span id="L576"><span class="lineNum">     576</span>              :           bias_decay, &quot;reverse_bias_ih&quot;, true);</span>
<span id="L577"><span class="lineNum">     577</span>              :         // reverse_bias_hh ( hidden bias ) : [ 1, 1, 1, NUM_GATE * unit ] -&gt;</span>
<span id="L578"><span class="lineNum">     578</span>              :         // i, f, g, o</span>
<span id="L579"><span class="lineNum">     579</span>              :         const TensorDim reverse_bias_hh_dim({NUM_GATE * unit},</span>
<span id="L580"><span class="lineNum">     580</span> <span class="tlaGNC">          12 :                                             weight_tensor_type);</span></span>
<span id="L581"><span class="lineNum">     581</span> <span class="tlaGNC">          24 :         wt_idx[LSTMParams::reverse_bias_hh] = context.requestWeight(</span></span>
<span id="L582"><span class="lineNum">     582</span>              :           reverse_bias_hh_dim, bias_initializer, WeightRegularizer::NONE, 1.0f,</span>
<span id="L583"><span class="lineNum">     583</span>              :           bias_decay, &quot;reverse_bias_hh&quot;, true);</span>
<span id="L584"><span class="lineNum">     584</span>              :       }</span>
<span id="L585"><span class="lineNum">     585</span>              :     }</span>
<span id="L586"><span class="lineNum">     586</span>              : </span>
<span id="L587"><span class="lineNum">     587</span>              :     // reverse_hidden_state_dim : [ batch_size, 1, max_timestep, unit ]</span>
<span id="L588"><span class="lineNum">     588</span>              :     const TensorDim reverse_hidden_state_dim(batch_size, 1, max_timestep, unit,</span>
<span id="L589"><span class="lineNum">     589</span> <span class="tlaGNC">          12 :                                              activation_tensor_type);</span></span>
<span id="L590"><span class="lineNum">     590</span> <span class="tlaGNC">          12 :     wt_idx[LSTMParams::reverse_hidden_state] = context.requestTensor(</span></span>
<span id="L591"><span class="lineNum">     591</span>              :       reverse_hidden_state_dim, &quot;reverse_hidden_state&quot;, Initializer::NONE, true,</span>
<span id="L592"><span class="lineNum">     592</span>              :       TensorLifespan::ITERATION_LIFESPAN);</span>
<span id="L593"><span class="lineNum">     593</span>              :     // reverse_cell_state_dim : [ batch_size, 1, max_timestep, unit ]</span>
<span id="L594"><span class="lineNum">     594</span>              :     const TensorDim reverse_cell_state_dim(batch_size, 1, max_timestep, unit,</span>
<span id="L595"><span class="lineNum">     595</span> <span class="tlaGNC">          12 :                                            activation_tensor_type);</span></span>
<span id="L596"><span class="lineNum">     596</span> <span class="tlaGNC">          12 :     wt_idx[LSTMParams::reverse_cell_state] = context.requestTensor(</span></span>
<span id="L597"><span class="lineNum">     597</span>              :       reverse_cell_state_dim, &quot;reverse_cell_state&quot;, Initializer::NONE, true,</span>
<span id="L598"><span class="lineNum">     598</span>              :       TensorLifespan::ITERATION_LIFESPAN);</span>
<span id="L599"><span class="lineNum">     599</span>              : </span>
<span id="L600"><span class="lineNum">     600</span>              :     // reverse_ifgo_dim : [ batch_size, 1, max_timestep, NUM_GATE * unit ]</span>
<span id="L601"><span class="lineNum">     601</span>              :     const TensorDim reverse_ifgo_dim(batch_size, 1, max_timestep,</span>
<span id="L602"><span class="lineNum">     602</span> <span class="tlaGNC">          12 :                                      NUM_GATE * unit, activation_tensor_type);</span></span>
<span id="L603"><span class="lineNum">     603</span> <span class="tlaGNC">          12 :     wt_idx[LSTMParams::reverse_ifgo] =</span></span>
<span id="L604"><span class="lineNum">     604</span> <span class="tlaGNC">          24 :       context.requestTensor(reverse_ifgo_dim, &quot;reverse_ifgo&quot;, Initializer::NONE,</span></span>
<span id="L605"><span class="lineNum">     605</span>              :                             true, TensorLifespan::ITERATION_LIFESPAN);</span>
<span id="L606"><span class="lineNum">     606</span>              :   }</span>
<span id="L607"><span class="lineNum">     607</span>              : </span>
<span id="L608"><span class="lineNum">     608</span> <span class="tlaGNC">          62 :   if (dropout_rate &gt; epsilon) {</span></span>
<span id="L609"><span class="lineNum">     609</span>              :     // dropout_mask_dim = [ batch, 1, time_iteration, unit ]</span>
<span id="L610"><span class="lineNum">     610</span>              :     const TensorDim dropout_mask_dim(batch_size, 1, max_timestep, unit,</span>
<span id="L611"><span class="lineNum">     611</span> <span class="tlaUNC tlaBgUNC">           0 :                                      activation_tensor_type);</span></span>
<span id="L612"><span class="lineNum">     612</span> <span class="tlaUNC">           0 :     wt_idx[LSTMParams::dropout_mask] =</span></span>
<span id="L613"><span class="lineNum">     613</span> <span class="tlaUNC">           0 :       context.requestTensor(dropout_mask_dim, &quot;dropout_mask&quot;, Initializer::NONE,</span></span>
<span id="L614"><span class="lineNum">     614</span>              :                             false, TensorLifespan::ITERATION_LIFESPAN);</span>
<span id="L615"><span class="lineNum">     615</span>              :   }</span>
<span id="L616"><span class="lineNum">     616</span>              : </span>
<span id="L617"><span class="lineNum">     617</span> <span class="tlaGNC tlaBgGNC">          62 :   if (context.getActivationDataType() == TensorDim::DataType::FP32) {</span></span>
<span id="L618"><span class="lineNum">     618</span> <span class="tlaGNC">          62 :     acti_func.setActiFunc&lt;float&gt;(hidden_state_activation_type);</span></span>
<span id="L619"><span class="lineNum">     619</span> <span class="tlaGNC">          62 :     recurrent_acti_func.setActiFunc&lt;float&gt;(recurrent_activation_type);</span></span>
<span id="L620"><span class="lineNum">     620</span> <span class="tlaUNC tlaBgUNC">           0 :   } else if (context.getActivationDataType() == TensorDim::DataType::FP16) {</span></span>
<span id="L621"><span class="lineNum">     621</span>              : #ifdef ENABLE_FP16</span>
<span id="L622"><span class="lineNum">     622</span>              :     acti_func.setActiFunc&lt;_FP16&gt;(hidden_state_activation_type);</span>
<span id="L623"><span class="lineNum">     623</span>              :     recurrent_acti_func.setActiFunc&lt;_FP16&gt;(recurrent_activation_type);</span>
<span id="L624"><span class="lineNum">     624</span>              : #else</span>
<span id="L625"><span class="lineNum">     625</span> <span class="tlaUNC">           0 :     throw std::invalid_argument(&quot;Error: enable-fp16 is not enabled&quot;);</span></span>
<span id="L626"><span class="lineNum">     626</span>              : #endif</span>
<span id="L627"><span class="lineNum">     627</span>              :   }</span>
<span id="L628"><span class="lineNum">     628</span> <span class="tlaGNC tlaBgGNC">          62 : }</span></span>
<span id="L629"><span class="lineNum">     629</span>              : </span>
<span id="L630"><span class="lineNum">     630</span> <span class="tlaGNC">         337 : void LSTMLayer::setProperty(const std::vector&lt;std::string&gt; &amp;values) {</span></span>
<span id="L631"><span class="lineNum">     631</span>              :   const std::vector&lt;std::string&gt; &amp;remain_props =</span>
<span id="L632"><span class="lineNum">     632</span> <span class="tlaGNC">         337 :     loadProperties(values, lstm_props);</span></span>
<span id="L633"><span class="lineNum">     633</span> <span class="tlaGNC">         336 :   LSTMCore::setProperty(remain_props);</span></span>
<span id="L634"><span class="lineNum">     634</span> <span class="tlaGNC">         336 : }</span></span>
<span id="L635"><span class="lineNum">     635</span>              : </span>
<span id="L636"><span class="lineNum">     636</span> <span class="tlaGNC">          26 : void LSTMLayer::exportTo(Exporter &amp;exporter,</span></span>
<span id="L637"><span class="lineNum">     637</span>              :                          const ml::train::ExportMethods &amp;method) const {</span>
<span id="L638"><span class="lineNum">     638</span> <span class="tlaGNC">          26 :   LSTMCore::exportTo(exporter, method);</span></span>
<span id="L639"><span class="lineNum">     639</span> <span class="tlaGNC">          26 :   exporter.saveResult(lstm_props, method, this);</span></span>
<span id="L640"><span class="lineNum">     640</span> <span class="tlaGNC">          26 : }</span></span>
<span id="L641"><span class="lineNum">     641</span>              : </span>
<span id="L642"><span class="lineNum">     642</span> <span class="tlaGNC">         171 : void LSTMLayer::forwarding(RunLayerContext &amp;context, bool training) {</span></span>
<span id="L643"><span class="lineNum">     643</span>              :   const bool disable_bias =</span>
<span id="L644"><span class="lineNum">     644</span> <span class="tlaGNC">         171 :     std::get&lt;props::DisableBias&gt;(*layer_impl_props).get();</span></span>
<span id="L645"><span class="lineNum">     645</span>              : </span>
<span id="L646"><span class="lineNum">     646</span> <span class="tlaGNC">         171 :   const unsigned int unit = std::get&lt;props::Unit&gt;(lstmcore_props).get();</span></span>
<span id="L647"><span class="lineNum">     647</span>              :   const bool integrate_bias =</span>
<span id="L648"><span class="lineNum">     648</span> <span class="tlaGNC">         171 :     std::get&lt;props::IntegrateBias&gt;(lstmcore_props).get();</span></span>
<span id="L649"><span class="lineNum">     649</span>              : </span>
<span id="L650"><span class="lineNum">     650</span>              :   const bool return_sequences =</span>
<span id="L651"><span class="lineNum">     651</span> <span class="tlaGNC">         171 :     std::get&lt;props::ReturnSequences&gt;(lstm_props).get();</span></span>
<span id="L652"><span class="lineNum">     652</span> <span class="tlaGNC">         171 :   const bool bidirectional = std::get&lt;props::Bidirectional&gt;(lstm_props).get();</span></span>
<span id="L653"><span class="lineNum">     653</span> <span class="tlaGNC">         171 :   const float dropout_rate = std::get&lt;props::DropOutRate&gt;(lstm_props).get();</span></span>
<span id="L654"><span class="lineNum">     654</span>              :   const unsigned int max_timestep =</span>
<span id="L655"><span class="lineNum">     655</span> <span class="tlaGNC">         171 :     std::get&lt;props::MaxTimestep&gt;(lstm_props).get();</span></span>
<span id="L656"><span class="lineNum">     656</span>              : </span>
<span id="L657"><span class="lineNum">     657</span> <span class="tlaGNC">         171 :   const unsigned int bidirectional_constant = bidirectional ? 2 : 1;</span></span>
<span id="L658"><span class="lineNum">     658</span> <span class="tlaGNC">         171 :   bool enable_dropout = dropout_rate &gt; epsilon &amp;&amp; training;</span></span>
<span id="L659"><span class="lineNum">     659</span>              : </span>
<span id="L660"><span class="lineNum">     660</span> <span class="tlaGNC">         171 :   const Tensor &amp;input = context.getInput(SINGLE_INOUT_IDX);</span></span>
<span id="L661"><span class="lineNum">     661</span> <span class="tlaGNC">         171 :   const TensorDim input_dim = input.getDim();</span></span>
<span id="L662"><span class="lineNum">     662</span> <span class="tlaGNC">         171 :   const unsigned int batch_size = input_dim.batch();</span></span>
<span id="L663"><span class="lineNum">     663</span> <span class="tlaGNC">         171 :   const unsigned int feature_size = input_dim.width();</span></span>
<span id="L664"><span class="lineNum">     664</span> <span class="tlaGNC">         171 :   Tensor &amp;output = context.getOutput(SINGLE_INOUT_IDX);</span></span>
<span id="L665"><span class="lineNum">     665</span>              : </span>
<span id="L666"><span class="lineNum">     666</span> <span class="tlaGNC">         171 :   const Tensor &amp;weight_ih = context.getWeight(wt_idx[LSTMParams::weight_ih]);</span></span>
<span id="L667"><span class="lineNum">     667</span> <span class="tlaGNC">         171 :   const Tensor &amp;weight_hh = context.getWeight(wt_idx[LSTMParams::weight_hh]);</span></span>
<span id="L668"><span class="lineNum">     668</span>              : </span>
<span id="L669"><span class="lineNum">     669</span>              :   Tensor empty =</span>
<span id="L670"><span class="lineNum">     670</span> <span class="tlaGNC">         171 :     Tensor(&quot;empty&quot;, weight_ih.getFormat(), weight_ih.getDataType());</span></span>
<span id="L671"><span class="lineNum">     671</span>              : </span>
<span id="L672"><span class="lineNum">     672</span> <span class="tlaGNC">         171 :   const Tensor &amp;bias_h = !disable_bias &amp;&amp; integrate_bias</span></span>
<span id="L673"><span class="lineNum">     673</span> <span class="tlaGNC">         171 :                            ? context.getWeight(wt_idx[LSTMParams::bias_h])</span></span>
<span id="L674"><span class="lineNum">     674</span>              :                            : empty;</span>
<span id="L675"><span class="lineNum">     675</span>              :   const Tensor &amp;bias_ih = !disable_bias &amp;&amp; !integrate_bias</span>
<span id="L676"><span class="lineNum">     676</span> <span class="tlaGNC">         171 :                             ? context.getWeight(wt_idx[LSTMParams::bias_ih])</span></span>
<span id="L677"><span class="lineNum">     677</span>              :                             : empty;</span>
<span id="L678"><span class="lineNum">     678</span>              :   const Tensor &amp;bias_hh = !disable_bias &amp;&amp; !integrate_bias</span>
<span id="L679"><span class="lineNum">     679</span> <span class="tlaGNC">         171 :                             ? context.getWeight(wt_idx[LSTMParams::bias_hh])</span></span>
<span id="L680"><span class="lineNum">     680</span>              :                             : empty;</span>
<span id="L681"><span class="lineNum">     681</span>              : </span>
<span id="L682"><span class="lineNum">     682</span> <span class="tlaGNC">         171 :   Tensor &amp;hidden_state = context.getTensor(wt_idx[LSTMParams::hidden_state]);</span></span>
<span id="L683"><span class="lineNum">     683</span> <span class="tlaGNC">         171 :   Tensor &amp;cell_state = context.getTensor(wt_idx[LSTMParams::cell_state]);</span></span>
<span id="L684"><span class="lineNum">     684</span> <span class="tlaGNC">         171 :   Tensor &amp;ifgo = context.getTensor(wt_idx[LSTMParams::ifgo]);</span></span>
<span id="L685"><span class="lineNum">     685</span>              : </span>
<span id="L686"><span class="lineNum">     686</span>              :   Tensor &amp;mask = enable_dropout</span>
<span id="L687"><span class="lineNum">     687</span> <span class="tlaGNC">         171 :                    ? context.getTensor(wt_idx[LSTMParams::dropout_mask])</span></span>
<span id="L688"><span class="lineNum">     688</span>              :                    : empty;</span>
<span id="L689"><span class="lineNum">     689</span> <span class="tlaGNC">         171 :   forwardingBatchFirstLSTM(NUM_GATE, batch_size, feature_size, disable_bias,</span></span>
<span id="L690"><span class="lineNum">     690</span> <span class="tlaGNC">         171 :                            unit, integrate_bias, acti_func, recurrent_acti_func,</span></span>
<span id="L691"><span class="lineNum">     691</span>              :                            enable_dropout, dropout_rate, max_timestep, false,</span>
<span id="L692"><span class="lineNum">     692</span>              :                            input, weight_ih, weight_hh, bias_h, bias_ih,</span>
<span id="L693"><span class="lineNum">     693</span>              :                            bias_hh, hidden_state, cell_state, ifgo, mask);</span>
<span id="L694"><span class="lineNum">     694</span> <span class="tlaGNC">         171 :   if (bidirectional) {</span></span>
<span id="L695"><span class="lineNum">     695</span>              :     const Tensor &amp;reverse_weight_ih =</span>
<span id="L696"><span class="lineNum">     696</span> <span class="tlaGNC">          18 :       context.getWeight(wt_idx[LSTMParams::reverse_weight_ih]);</span></span>
<span id="L697"><span class="lineNum">     697</span>              :     const Tensor &amp;reverse_weight_hh =</span>
<span id="L698"><span class="lineNum">     698</span> <span class="tlaGNC">          18 :       context.getWeight(wt_idx[LSTMParams::reverse_weight_hh]);</span></span>
<span id="L699"><span class="lineNum">     699</span>              :     const Tensor &amp;reverse_bias_h =</span>
<span id="L700"><span class="lineNum">     700</span>              :       !disable_bias &amp;&amp; integrate_bias</span>
<span id="L701"><span class="lineNum">     701</span> <span class="tlaGNC">          18 :         ? context.getWeight(wt_idx[LSTMParams::reverse_bias_h])</span></span>
<span id="L702"><span class="lineNum">     702</span>              :         : empty;</span>
<span id="L703"><span class="lineNum">     703</span>              :     const Tensor &amp;reverse_bias_ih =</span>
<span id="L704"><span class="lineNum">     704</span>              :       !disable_bias &amp;&amp; !integrate_bias</span>
<span id="L705"><span class="lineNum">     705</span> <span class="tlaGNC">          18 :         ? context.getWeight(wt_idx[LSTMParams::reverse_bias_ih])</span></span>
<span id="L706"><span class="lineNum">     706</span>              :         : empty;</span>
<span id="L707"><span class="lineNum">     707</span>              :     const Tensor &amp;reverse_bias_hh =</span>
<span id="L708"><span class="lineNum">     708</span>              :       !disable_bias &amp;&amp; !integrate_bias</span>
<span id="L709"><span class="lineNum">     709</span> <span class="tlaGNC">          18 :         ? context.getWeight(wt_idx[LSTMParams::reverse_bias_hh])</span></span>
<span id="L710"><span class="lineNum">     710</span>              :         : empty;</span>
<span id="L711"><span class="lineNum">     711</span>              : </span>
<span id="L712"><span class="lineNum">     712</span>              :     Tensor &amp;reverse_hidden_state =</span>
<span id="L713"><span class="lineNum">     713</span> <span class="tlaGNC">          18 :       context.getTensor(wt_idx[LSTMParams::reverse_hidden_state]);</span></span>
<span id="L714"><span class="lineNum">     714</span>              :     Tensor &amp;reverse_cell_state =</span>
<span id="L715"><span class="lineNum">     715</span> <span class="tlaGNC">          18 :       context.getTensor(wt_idx[LSTMParams::reverse_cell_state]);</span></span>
<span id="L716"><span class="lineNum">     716</span> <span class="tlaGNC">          18 :     Tensor &amp;reverse_ifgo = context.getTensor(wt_idx[LSTMParams::reverse_ifgo]);</span></span>
<span id="L717"><span class="lineNum">     717</span>              : </span>
<span id="L718"><span class="lineNum">     718</span> <span class="tlaGNC">          18 :     forwardingBatchFirstLSTM(</span></span>
<span id="L719"><span class="lineNum">     719</span>              :       NUM_GATE, batch_size, feature_size, disable_bias, unit, integrate_bias,</span>
<span id="L720"><span class="lineNum">     720</span>              :       acti_func, recurrent_acti_func, enable_dropout, dropout_rate,</span>
<span id="L721"><span class="lineNum">     721</span>              :       max_timestep, true, input, reverse_weight_ih, reverse_weight_hh,</span>
<span id="L722"><span class="lineNum">     722</span>              :       reverse_bias_h, reverse_bias_ih, reverse_bias_hh, reverse_hidden_state,</span>
<span id="L723"><span class="lineNum">     723</span>              :       reverse_cell_state, reverse_ifgo, mask);</span>
<span id="L724"><span class="lineNum">     724</span>              :   }</span>
<span id="L725"><span class="lineNum">     725</span>              : </span>
<span id="L726"><span class="lineNum">     726</span> <span class="tlaGNC">         171 :   if (return_sequences &amp;&amp; !bidirectional) {</span></span>
<span id="L727"><span class="lineNum">     727</span> <span class="tlaGNC">          98 :     if (hidden_state.getDataType() == TensorDim::DataType::FP32) {</span></span>
<span id="L728"><span class="lineNum">     728</span> <span class="tlaGNC">          98 :       std::copy(hidden_state.getData&lt;float&gt;(),</span></span>
<span id="L729"><span class="lineNum">     729</span> <span class="tlaGNC">          98 :                 hidden_state.getData&lt;float&gt;() + hidden_state.size(),</span></span>
<span id="L730"><span class="lineNum">     730</span>              :                 output.getData&lt;float&gt;());</span>
<span id="L731"><span class="lineNum">     731</span> <span class="tlaUNC tlaBgUNC">           0 :     } else if (hidden_state.getDataType() == TensorDim::DataType::FP16) {</span></span>
<span id="L732"><span class="lineNum">     732</span>              : #ifdef ENABLE_FP16</span>
<span id="L733"><span class="lineNum">     733</span>              :       std::copy(hidden_state.getData&lt;_FP16&gt;(),</span>
<span id="L734"><span class="lineNum">     734</span>              :                 hidden_state.getData&lt;_FP16&gt;() + hidden_state.size(),</span>
<span id="L735"><span class="lineNum">     735</span>              :                 output.getData&lt;_FP16&gt;());</span>
<span id="L736"><span class="lineNum">     736</span>              : #else</span>
<span id="L737"><span class="lineNum">     737</span> <span class="tlaUNC">           0 :       throw std::invalid_argument(&quot;Error: enable-fp16 is not enabled&quot;);</span></span>
<span id="L738"><span class="lineNum">     738</span>              : #endif</span>
<span id="L739"><span class="lineNum">     739</span>              :     }</span>
<span id="L740"><span class="lineNum">     740</span>              :   } else {</span>
<span id="L741"><span class="lineNum">     741</span> <span class="tlaGNC tlaBgGNC">          73 :     unsigned int end_timestep = return_sequences ? max_timestep : 1;</span></span>
<span id="L742"><span class="lineNum">     742</span> <span class="tlaGNC">          73 :     if (hidden_state.getDataType() == TensorDim::DataType::FP32) {</span></span>
<span id="L743"><span class="lineNum">     743</span> <span class="tlaGNC">         217 :       for (unsigned int batch = 0; batch &lt; batch_size; ++batch) {</span></span>
<span id="L744"><span class="lineNum">     744</span> <span class="tlaGNC">         342 :         for (unsigned int timestep = 0; timestep &lt; end_timestep; ++timestep) {</span></span>
<span id="L745"><span class="lineNum">     745</span> <span class="tlaGNC">         198 :           float *hidden_state_data = hidden_state.getAddress&lt;float&gt;(</span></span>
<span id="L746"><span class="lineNum">     746</span> <span class="tlaGNC">         198 :             batch * max_timestep * unit +</span></span>
<span id="L747"><span class="lineNum">     747</span> <span class="tlaGNC">         198 :             (return_sequences ? 0 : (max_timestep - 1) * unit) +</span></span>
<span id="L748"><span class="lineNum">     748</span>              :             timestep * unit);</span>
<span id="L749"><span class="lineNum">     749</span> <span class="tlaGNC">         198 :           float *output_data = output.getAddress&lt;float&gt;(</span></span>
<span id="L750"><span class="lineNum">     750</span> <span class="tlaGNC">         198 :             batch * (return_sequences ? max_timestep : 1) *</span></span>
<span id="L751"><span class="lineNum">     751</span> <span class="tlaGNC">         198 :               bidirectional_constant * unit +</span></span>
<span id="L752"><span class="lineNum">     752</span>              :             timestep * bidirectional_constant * unit);</span>
<span id="L753"><span class="lineNum">     753</span> <span class="tlaGNC">         198 :           std::copy(hidden_state_data, hidden_state_data + unit, output_data);</span></span>
<span id="L754"><span class="lineNum">     754</span>              : </span>
<span id="L755"><span class="lineNum">     755</span> <span class="tlaGNC">         198 :           if (bidirectional) {</span></span>
<span id="L756"><span class="lineNum">     756</span>              :             Tensor &amp;reverse_hidden_state =</span>
<span id="L757"><span class="lineNum">     757</span> <span class="tlaGNC">         108 :               context.getTensor(wt_idx[LSTMParams::reverse_hidden_state]);</span></span>
<span id="L758"><span class="lineNum">     758</span>              :             float *reverse_hidden_state_data =</span>
<span id="L759"><span class="lineNum">     759</span>              :               reverse_hidden_state.getAddress&lt;float&gt;(</span>
<span id="L760"><span class="lineNum">     760</span>              :                 batch * max_timestep * unit +</span>
<span id="L761"><span class="lineNum">     761</span>              :                 (return_sequences ? 0 : (max_timestep - 1) * unit) +</span>
<span id="L762"><span class="lineNum">     762</span>              :                 timestep * unit);</span>
<span id="L763"><span class="lineNum">     763</span> <span class="tlaGNC">         108 :             std::copy(reverse_hidden_state_data,</span></span>
<span id="L764"><span class="lineNum">     764</span>              :                       reverse_hidden_state_data + unit, output_data + unit);</span>
<span id="L765"><span class="lineNum">     765</span>              :           }</span>
<span id="L766"><span class="lineNum">     766</span>              :         }</span>
<span id="L767"><span class="lineNum">     767</span>              :       }</span>
<span id="L768"><span class="lineNum">     768</span> <span class="tlaUNC tlaBgUNC">           0 :     } else if (hidden_state.getDataType() == TensorDim::DataType::FP16) {</span></span>
<span id="L769"><span class="lineNum">     769</span>              : #ifdef ENABLE_FP16</span>
<span id="L770"><span class="lineNum">     770</span>              :       for (unsigned int batch = 0; batch &lt; batch_size; ++batch) {</span>
<span id="L771"><span class="lineNum">     771</span>              :         for (unsigned int timestep = 0; timestep &lt; end_timestep; ++timestep) {</span>
<span id="L772"><span class="lineNum">     772</span>              :           _FP16 *hidden_state_data = hidden_state.getAddress&lt;_FP16&gt;(</span>
<span id="L773"><span class="lineNum">     773</span>              :             batch * max_timestep * unit +</span>
<span id="L774"><span class="lineNum">     774</span>              :             (return_sequences ? 0 : (max_timestep - 1) * unit) +</span>
<span id="L775"><span class="lineNum">     775</span>              :             timestep * unit);</span>
<span id="L776"><span class="lineNum">     776</span>              :           _FP16 *output_data = output.getAddress&lt;_FP16&gt;(</span>
<span id="L777"><span class="lineNum">     777</span>              :             batch * (return_sequences ? max_timestep : 1) *</span>
<span id="L778"><span class="lineNum">     778</span>              :               bidirectional_constant * unit +</span>
<span id="L779"><span class="lineNum">     779</span>              :             timestep * bidirectional_constant * unit);</span>
<span id="L780"><span class="lineNum">     780</span>              :           std::copy(hidden_state_data, hidden_state_data + unit, output_data);</span>
<span id="L781"><span class="lineNum">     781</span>              : </span>
<span id="L782"><span class="lineNum">     782</span>              :           if (bidirectional) {</span>
<span id="L783"><span class="lineNum">     783</span>              :             Tensor &amp;reverse_hidden_state =</span>
<span id="L784"><span class="lineNum">     784</span>              :               context.getTensor(wt_idx[LSTMParams::reverse_hidden_state]);</span>
<span id="L785"><span class="lineNum">     785</span>              :             _FP16 *reverse_hidden_state_data =</span>
<span id="L786"><span class="lineNum">     786</span>              :               reverse_hidden_state.getAddress&lt;_FP16&gt;(</span>
<span id="L787"><span class="lineNum">     787</span>              :                 batch * max_timestep * unit +</span>
<span id="L788"><span class="lineNum">     788</span>              :                 (return_sequences ? 0 : (max_timestep - 1) * unit) +</span>
<span id="L789"><span class="lineNum">     789</span>              :                 timestep * unit);</span>
<span id="L790"><span class="lineNum">     790</span>              :             std::copy(reverse_hidden_state_data,</span>
<span id="L791"><span class="lineNum">     791</span>              :                       reverse_hidden_state_data + unit, output_data + unit);</span>
<span id="L792"><span class="lineNum">     792</span>              :           }</span>
<span id="L793"><span class="lineNum">     793</span>              :         }</span>
<span id="L794"><span class="lineNum">     794</span>              :       }</span>
<span id="L795"><span class="lineNum">     795</span>              : #else</span>
<span id="L796"><span class="lineNum">     796</span> <span class="tlaUNC">           0 :       throw std::invalid_argument(&quot;Error: enable-fp16 is not enabled&quot;);</span></span>
<span id="L797"><span class="lineNum">     797</span>              : #endif</span>
<span id="L798"><span class="lineNum">     798</span>              :     }</span>
<span id="L799"><span class="lineNum">     799</span>              :   }</span>
<span id="L800"><span class="lineNum">     800</span> <span class="tlaGNC tlaBgGNC">         171 : }</span></span>
<span id="L801"><span class="lineNum">     801</span>              : </span>
<span id="L802"><span class="lineNum">     802</span> <span class="tlaGNC">         101 : void LSTMLayer::calcDerivative(RunLayerContext &amp;context) {</span></span>
<span id="L803"><span class="lineNum">     803</span> <span class="tlaGNC">         101 :   const bool bidirectional = std::get&lt;props::Bidirectional&gt;(lstm_props).get();</span></span>
<span id="L804"><span class="lineNum">     804</span>              : </span>
<span id="L805"><span class="lineNum">     805</span> <span class="tlaGNC">         101 :   Tensor &amp;outgoing_derivative = context.getOutgoingDerivative(SINGLE_INOUT_IDX);</span></span>
<span id="L806"><span class="lineNum">     806</span> <span class="tlaGNC">         101 :   const Tensor &amp;weight_ih = context.getWeight(wt_idx[LSTMParams::weight_ih]);</span></span>
<span id="L807"><span class="lineNum">     807</span> <span class="tlaGNC">         101 :   const Tensor &amp;d_ifgos = context.getTensorGrad(wt_idx[LSTMParams::ifgo]);</span></span>
<span id="L808"><span class="lineNum">     808</span>              : </span>
<span id="L809"><span class="lineNum">     809</span> <span class="tlaGNC">         101 :   calcDerivativeLSTM(outgoing_derivative, weight_ih, d_ifgos);</span></span>
<span id="L810"><span class="lineNum">     810</span>              : </span>
<span id="L811"><span class="lineNum">     811</span> <span class="tlaGNC">         101 :   if (bidirectional) {</span></span>
<span id="L812"><span class="lineNum">     812</span>              :     const Tensor &amp;reverse_weight_ih =</span>
<span id="L813"><span class="lineNum">     813</span> <span class="tlaGNC">           9 :       context.getWeight(wt_idx[LSTMParams::reverse_weight_ih]);</span></span>
<span id="L814"><span class="lineNum">     814</span>              :     const Tensor &amp;reverse_d_ifgos =</span>
<span id="L815"><span class="lineNum">     815</span> <span class="tlaGNC">           9 :       context.getTensorGrad(wt_idx[LSTMParams::reverse_ifgo]);</span></span>
<span id="L816"><span class="lineNum">     816</span>              : </span>
<span id="L817"><span class="lineNum">     817</span> <span class="tlaGNC">           9 :     calcDerivativeLSTM(outgoing_derivative, reverse_weight_ih, reverse_d_ifgos,</span></span>
<span id="L818"><span class="lineNum">     818</span>              :                        1.0f);</span>
<span id="L819"><span class="lineNum">     819</span>              :   }</span>
<span id="L820"><span class="lineNum">     820</span> <span class="tlaGNC">         101 : }</span></span>
<span id="L821"><span class="lineNum">     821</span>              : </span>
<span id="L822"><span class="lineNum">     822</span> <span class="tlaGNC">         101 : void LSTMLayer::calcGradient(RunLayerContext &amp;context) {</span></span>
<span id="L823"><span class="lineNum">     823</span>              :   const bool disable_bias =</span>
<span id="L824"><span class="lineNum">     824</span> <span class="tlaGNC">         101 :     std::get&lt;props::DisableBias&gt;(*layer_impl_props).get();</span></span>
<span id="L825"><span class="lineNum">     825</span>              : </span>
<span id="L826"><span class="lineNum">     826</span> <span class="tlaGNC">         101 :   const unsigned int unit = std::get&lt;props::Unit&gt;(lstmcore_props).get();</span></span>
<span id="L827"><span class="lineNum">     827</span>              :   const bool integrate_bias =</span>
<span id="L828"><span class="lineNum">     828</span> <span class="tlaGNC">         101 :     std::get&lt;props::IntegrateBias&gt;(lstmcore_props).get();</span></span>
<span id="L829"><span class="lineNum">     829</span>              : </span>
<span id="L830"><span class="lineNum">     830</span>              :   const bool return_sequences =</span>
<span id="L831"><span class="lineNum">     831</span> <span class="tlaGNC">         101 :     std::get&lt;props::ReturnSequences&gt;(lstm_props).get();</span></span>
<span id="L832"><span class="lineNum">     832</span> <span class="tlaGNC">         101 :   const bool bidirectional = std::get&lt;props::Bidirectional&gt;(lstm_props).get();</span></span>
<span id="L833"><span class="lineNum">     833</span> <span class="tlaGNC">         101 :   const float dropout_rate = std::get&lt;props::DropOutRate&gt;(lstm_props).get();</span></span>
<span id="L834"><span class="lineNum">     834</span>              :   const unsigned int max_timestep =</span>
<span id="L835"><span class="lineNum">     835</span> <span class="tlaGNC">         101 :     std::get&lt;props::MaxTimestep&gt;(lstm_props).get();</span></span>
<span id="L836"><span class="lineNum">     836</span>              : </span>
<span id="L837"><span class="lineNum">     837</span> <span class="tlaGNC">         101 :   bool enable_dropout = dropout_rate &gt; epsilon;</span></span>
<span id="L838"><span class="lineNum">     838</span>              : </span>
<span id="L839"><span class="lineNum">     839</span> <span class="tlaGNC">         101 :   const Tensor &amp;input = context.getInput(SINGLE_INOUT_IDX);</span></span>
<span id="L840"><span class="lineNum">     840</span>              :   const Tensor &amp;incoming_derivative =</span>
<span id="L841"><span class="lineNum">     841</span> <span class="tlaGNC">         101 :     context.getIncomingDerivative(SINGLE_INOUT_IDX);</span></span>
<span id="L842"><span class="lineNum">     842</span> <span class="tlaGNC">         101 :   const TensorDim input_dim = input.getDim();</span></span>
<span id="L843"><span class="lineNum">     843</span> <span class="tlaGNC">         101 :   const unsigned int batch_size = input_dim.batch();</span></span>
<span id="L844"><span class="lineNum">     844</span> <span class="tlaGNC">         101 :   const unsigned int feature_size = input_dim.width();</span></span>
<span id="L845"><span class="lineNum">     845</span>              : </span>
<span id="L846"><span class="lineNum">     846</span> <span class="tlaGNC">         101 :   Tensor &amp;d_weight_ih = context.getWeightGrad(wt_idx[LSTMParams::weight_ih]);</span></span>
<span id="L847"><span class="lineNum">     847</span> <span class="tlaGNC">         101 :   const Tensor &amp;weight_hh = context.getWeight(wt_idx[LSTMParams::weight_hh]);</span></span>
<span id="L848"><span class="lineNum">     848</span> <span class="tlaGNC">         101 :   Tensor &amp;d_weight_hh = context.getWeightGrad(wt_idx[LSTMParams::weight_hh]);</span></span>
<span id="L849"><span class="lineNum">     849</span>              : </span>
<span id="L850"><span class="lineNum">     850</span>              :   Tensor empty =</span>
<span id="L851"><span class="lineNum">     851</span> <span class="tlaGNC">         101 :     Tensor(&quot;empty&quot;, weight_hh.getFormat(), weight_hh.getDataType());</span></span>
<span id="L852"><span class="lineNum">     852</span>              : </span>
<span id="L853"><span class="lineNum">     853</span> <span class="tlaGNC">         101 :   Tensor &amp;d_bias_h = !disable_bias &amp;&amp; integrate_bias</span></span>
<span id="L854"><span class="lineNum">     854</span> <span class="tlaGNC">         101 :                        ? context.getWeightGrad(wt_idx[LSTMParams::bias_h])</span></span>
<span id="L855"><span class="lineNum">     855</span>              :                        : empty;</span>
<span id="L856"><span class="lineNum">     856</span>              :   Tensor &amp;d_bias_ih = !disable_bias &amp;&amp; !integrate_bias</span>
<span id="L857"><span class="lineNum">     857</span> <span class="tlaGNC">         101 :                         ? context.getWeightGrad(wt_idx[LSTMParams::bias_ih])</span></span>
<span id="L858"><span class="lineNum">     858</span>              :                         : empty;</span>
<span id="L859"><span class="lineNum">     859</span>              :   Tensor &amp;d_bias_hh = !disable_bias &amp;&amp; !integrate_bias</span>
<span id="L860"><span class="lineNum">     860</span> <span class="tlaGNC">         101 :                         ? context.getWeightGrad(wt_idx[LSTMParams::bias_hh])</span></span>
<span id="L861"><span class="lineNum">     861</span>              :                         : empty;</span>
<span id="L862"><span class="lineNum">     862</span>              : </span>
<span id="L863"><span class="lineNum">     863</span>              :   const Tensor &amp;hidden_state =</span>
<span id="L864"><span class="lineNum">     864</span> <span class="tlaGNC">         101 :     context.getTensor(wt_idx[LSTMParams::hidden_state]);</span></span>
<span id="L865"><span class="lineNum">     865</span>              :   Tensor &amp;d_hidden_state =</span>
<span id="L866"><span class="lineNum">     866</span> <span class="tlaGNC">         101 :     context.getTensorGrad(wt_idx[LSTMParams::hidden_state]);</span></span>
<span id="L867"><span class="lineNum">     867</span> <span class="tlaGNC">         101 :   const Tensor &amp;cell_state = context.getTensor(wt_idx[LSTMParams::cell_state]);</span></span>
<span id="L868"><span class="lineNum">     868</span> <span class="tlaGNC">         101 :   Tensor &amp;d_cell_state = context.getTensorGrad(wt_idx[LSTMParams::cell_state]);</span></span>
<span id="L869"><span class="lineNum">     869</span>              : </span>
<span id="L870"><span class="lineNum">     870</span> <span class="tlaGNC">         101 :   const Tensor &amp;ifgo = context.getTensor(wt_idx[LSTMParams::ifgo]);</span></span>
<span id="L871"><span class="lineNum">     871</span> <span class="tlaGNC">         101 :   Tensor &amp;d_ifgo = context.getTensorGrad(wt_idx[LSTMParams::ifgo]);</span></span>
<span id="L872"><span class="lineNum">     872</span>              : </span>
<span id="L873"><span class="lineNum">     873</span>              :   const Tensor &amp;mask = enable_dropout</span>
<span id="L874"><span class="lineNum">     874</span> <span class="tlaGNC">         101 :                          ? context.getTensor(wt_idx[LSTMParams::dropout_mask])</span></span>
<span id="L875"><span class="lineNum">     875</span>              :                          : empty;</span>
<span id="L876"><span class="lineNum">     876</span>              : </span>
<span id="L877"><span class="lineNum">     877</span> <span class="tlaGNC">         101 :   calcGradientBatchFirstLSTM(</span></span>
<span id="L878"><span class="lineNum">     878</span>              :     NUM_GATE, batch_size, feature_size, disable_bias, unit, integrate_bias,</span>
<span id="L879"><span class="lineNum">     879</span> <span class="tlaGNC">         101 :     acti_func, recurrent_acti_func, return_sequences, bidirectional,</span></span>
<span id="L880"><span class="lineNum">     880</span>              :     enable_dropout, dropout_rate, max_timestep, false, input,</span>
<span id="L881"><span class="lineNum">     881</span>              :     incoming_derivative, d_weight_ih, weight_hh, d_weight_hh, d_bias_h,</span>
<span id="L882"><span class="lineNum">     882</span>              :     d_bias_ih, d_bias_hh, hidden_state, d_hidden_state, cell_state,</span>
<span id="L883"><span class="lineNum">     883</span>              :     d_cell_state, ifgo, d_ifgo, mask);</span>
<span id="L884"><span class="lineNum">     884</span>              : </span>
<span id="L885"><span class="lineNum">     885</span> <span class="tlaGNC">         101 :   if (bidirectional) {</span></span>
<span id="L886"><span class="lineNum">     886</span>              :     Tensor &amp;reverse_d_weight_ih =</span>
<span id="L887"><span class="lineNum">     887</span> <span class="tlaGNC">           9 :       context.getWeightGrad(wt_idx[LSTMParams::reverse_weight_ih]);</span></span>
<span id="L888"><span class="lineNum">     888</span>              :     const Tensor &amp;reverse_weight_hh =</span>
<span id="L889"><span class="lineNum">     889</span> <span class="tlaGNC">           9 :       context.getWeight(wt_idx[LSTMParams::reverse_weight_hh]);</span></span>
<span id="L890"><span class="lineNum">     890</span>              :     Tensor &amp;reverse_d_weight_hh =</span>
<span id="L891"><span class="lineNum">     891</span> <span class="tlaGNC">           9 :       context.getWeightGrad(wt_idx[LSTMParams::reverse_weight_hh]);</span></span>
<span id="L892"><span class="lineNum">     892</span>              :     Tensor &amp;reverse_d_bias_h =</span>
<span id="L893"><span class="lineNum">     893</span>              :       !disable_bias &amp;&amp; integrate_bias</span>
<span id="L894"><span class="lineNum">     894</span> <span class="tlaGNC">           9 :         ? context.getWeightGrad(wt_idx[LSTMParams::reverse_bias_h])</span></span>
<span id="L895"><span class="lineNum">     895</span>              :         : empty;</span>
<span id="L896"><span class="lineNum">     896</span>              :     Tensor &amp;reverse_d_bias_ih =</span>
<span id="L897"><span class="lineNum">     897</span>              :       !disable_bias &amp;&amp; !integrate_bias</span>
<span id="L898"><span class="lineNum">     898</span> <span class="tlaGNC">           9 :         ? context.getWeightGrad(wt_idx[LSTMParams::reverse_bias_ih])</span></span>
<span id="L899"><span class="lineNum">     899</span>              :         : empty;</span>
<span id="L900"><span class="lineNum">     900</span>              :     Tensor &amp;reverse_d_bias_hh =</span>
<span id="L901"><span class="lineNum">     901</span>              :       !disable_bias &amp;&amp; !integrate_bias</span>
<span id="L902"><span class="lineNum">     902</span> <span class="tlaGNC">           9 :         ? context.getWeightGrad(wt_idx[LSTMParams::reverse_bias_hh])</span></span>
<span id="L903"><span class="lineNum">     903</span>              :         : empty;</span>
<span id="L904"><span class="lineNum">     904</span>              : </span>
<span id="L905"><span class="lineNum">     905</span>              :     const Tensor &amp;reverse_hidden_state =</span>
<span id="L906"><span class="lineNum">     906</span> <span class="tlaGNC">           9 :       context.getTensor(wt_idx[LSTMParams::reverse_hidden_state]);</span></span>
<span id="L907"><span class="lineNum">     907</span>              :     Tensor &amp;reverse_d_hidden_state =</span>
<span id="L908"><span class="lineNum">     908</span> <span class="tlaGNC">           9 :       context.getTensorGrad(wt_idx[LSTMParams::reverse_hidden_state]);</span></span>
<span id="L909"><span class="lineNum">     909</span>              :     const Tensor &amp;reverse_cell_state =</span>
<span id="L910"><span class="lineNum">     910</span> <span class="tlaGNC">           9 :       context.getTensor(wt_idx[LSTMParams::reverse_cell_state]);</span></span>
<span id="L911"><span class="lineNum">     911</span>              :     Tensor &amp;reverse_d_cell_state =</span>
<span id="L912"><span class="lineNum">     912</span> <span class="tlaGNC">           9 :       context.getTensorGrad(wt_idx[LSTMParams::reverse_cell_state]);</span></span>
<span id="L913"><span class="lineNum">     913</span>              : </span>
<span id="L914"><span class="lineNum">     914</span>              :     const Tensor &amp;reverse_ifgo =</span>
<span id="L915"><span class="lineNum">     915</span> <span class="tlaGNC">           9 :       context.getTensor(wt_idx[LSTMParams::reverse_ifgo]);</span></span>
<span id="L916"><span class="lineNum">     916</span>              :     Tensor &amp;reverse_d_ifgo =</span>
<span id="L917"><span class="lineNum">     917</span> <span class="tlaGNC">           9 :       context.getTensorGrad(wt_idx[LSTMParams::reverse_ifgo]);</span></span>
<span id="L918"><span class="lineNum">     918</span>              : </span>
<span id="L919"><span class="lineNum">     919</span> <span class="tlaGNC">           9 :     calcGradientBatchFirstLSTM(</span></span>
<span id="L920"><span class="lineNum">     920</span>              :       NUM_GATE, batch_size, feature_size, disable_bias, unit, integrate_bias,</span>
<span id="L921"><span class="lineNum">     921</span>              :       acti_func, recurrent_acti_func, return_sequences, bidirectional,</span>
<span id="L922"><span class="lineNum">     922</span>              :       enable_dropout, dropout_rate, max_timestep, true, input,</span>
<span id="L923"><span class="lineNum">     923</span>              :       incoming_derivative, reverse_d_weight_ih, reverse_weight_hh,</span>
<span id="L924"><span class="lineNum">     924</span>              :       reverse_d_weight_hh, reverse_d_bias_h, reverse_d_bias_ih,</span>
<span id="L925"><span class="lineNum">     925</span>              :       reverse_d_bias_hh, reverse_hidden_state, reverse_d_hidden_state,</span>
<span id="L926"><span class="lineNum">     926</span>              :       reverse_cell_state, reverse_d_cell_state, reverse_ifgo, reverse_d_ifgo,</span>
<span id="L927"><span class="lineNum">     927</span>              :       mask);</span>
<span id="L928"><span class="lineNum">     928</span>              :   }</span>
<span id="L929"><span class="lineNum">     929</span> <span class="tlaGNC">         101 : }</span></span>
<span id="L930"><span class="lineNum">     930</span>              : </span>
<span id="L931"><span class="lineNum">     931</span> <span class="tlaGNC">          36 : void LSTMLayer::setBatch(RunLayerContext &amp;context, unsigned int batch) {</span></span>
<span id="L932"><span class="lineNum">     932</span> <span class="tlaGNC">          36 :   const bool bidirectional = std::get&lt;props::Bidirectional&gt;(lstm_props).get();</span></span>
<span id="L933"><span class="lineNum">     933</span> <span class="tlaGNC">          36 :   const float dropout_rate = std::get&lt;props::DropOutRate&gt;(lstm_props).get();</span></span>
<span id="L934"><span class="lineNum">     934</span>              : </span>
<span id="L935"><span class="lineNum">     935</span> <span class="tlaGNC">          36 :   context.updateTensor(wt_idx[LSTMParams::hidden_state], batch);</span></span>
<span id="L936"><span class="lineNum">     936</span> <span class="tlaGNC">          36 :   context.updateTensor(wt_idx[LSTMParams::cell_state], batch);</span></span>
<span id="L937"><span class="lineNum">     937</span> <span class="tlaGNC">          36 :   context.updateTensor(wt_idx[LSTMParams::ifgo], batch);</span></span>
<span id="L938"><span class="lineNum">     938</span>              : </span>
<span id="L939"><span class="lineNum">     939</span> <span class="tlaGNC">          36 :   if (bidirectional) {</span></span>
<span id="L940"><span class="lineNum">     940</span> <span class="tlaGNC">          12 :     context.updateTensor(wt_idx[LSTMParams::reverse_hidden_state], batch);</span></span>
<span id="L941"><span class="lineNum">     941</span> <span class="tlaGNC">          12 :     context.updateTensor(wt_idx[LSTMParams::reverse_cell_state], batch);</span></span>
<span id="L942"><span class="lineNum">     942</span> <span class="tlaGNC">          12 :     context.updateTensor(wt_idx[LSTMParams::reverse_ifgo], batch);</span></span>
<span id="L943"><span class="lineNum">     943</span>              :   }</span>
<span id="L944"><span class="lineNum">     944</span>              : </span>
<span id="L945"><span class="lineNum">     945</span> <span class="tlaGNC">          36 :   if (dropout_rate &gt; epsilon) {</span></span>
<span id="L946"><span class="lineNum">     946</span> <span class="tlaUNC tlaBgUNC">           0 :     context.updateTensor(wt_idx[LSTMParams::dropout_mask], batch);</span></span>
<span id="L947"><span class="lineNum">     947</span>              :   }</span>
<span id="L948"><span class="lineNum">     948</span> <span class="tlaGNC tlaBgGNC">          36 : }</span></span>
<span id="L949"><span class="lineNum">     949</span>              : </span>
<span id="L950"><span class="lineNum">     950</span>              : } // namespace nntrainer</span>
        </pre>
              </td>
            </tr>
          </table>
          <br>

          <table width="100%" border=0 cellspacing=0 cellpadding=0>
            <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
            <tr><td class="versionInfo">Generated by: <a href="https://github.com//linux-test-project/lcov" target="_parent">LCOV version 2.0-1</a></td></tr>
          </table>
          <br>

</body>
</html>
